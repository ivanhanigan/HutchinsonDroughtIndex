#+TITLE:HutchinsonDroughtIndex 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----
* TODO-list
** news story
- http://mobile.abc.net.au/news/2015-07-06/drought-worries-rising-victoria-south-australia-rainfall-lowest/6597870
** build
devtools::build()
  ‘HutchinsonDroughtIndex/inst/extdata/GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv’

[1] "/home/ivan_hanigan/projects/HutchinsonDroughtIndex_1.1.tar.gz"
> install.packages("~/projects/HutchinsonDroughtIndex_1.1.tar.gz", repos = NULL, type = "source")
rm these after as clutter
* Introduction

** package doc
#+name:swishdbtools-package
#+begin_src R :session *R* :tangle man/HutchinsonDroughtIndex-package.Rd :exports none :eval no
  \name{HutchinsonDroughtIndex-package}
  \alias{HutchinsonDroughtIndex-package}
  \alias{HutchinsonDroughtIndex}
  \docType{package}
  \title{
  Hutchinson Drought Index
  }
  \description{
  Climatic Drought
  }
  \details{
  \tabular{ll}{
  Package: \tab HutchinsonDroughtIndex\cr
  Type: \tab Package\cr
  Version: \tab 1.1\cr
  Date: \tab 2015-11-06\cr
  License: \tab GPL2\cr
  }
  The package is designed to take a timeseries for a single location such as region or weather station and compute the drought index.  Dev work on grid version.
  }
  \author{
  
  
  Maintainer: <ivan.hanigan@gmail.com>
  
  }
  \references{
  
  Smith, D. I, Hutchinson, M. F, & McArthur, R. J. (1992) Climatic and
  Agricultural Drought: Payments and Policy. (Centre for Resource and
  Environmental Studies, Australian National University, Canberra,
  Australia). http://fennerschool-research.anu.edu.au/spatio-temporal/publications/cres_paper1992.pdf
  
  Hanigan, IC. 2012. The Hutchinson Drought Index Algorithm [Computer
  Software].  https://github.com/ivanhanigan/HutchinsonDroughtIndex
  
  }
  
#+end_src

** run tests
#+name:test_project
#+begin_src R :session *R* :tangle test_project.r :exports none :eval no
  ################################################################
  # name:test_project
  require(testthat)
  test_dir('tests')
  
#+end_src

** DEPRECATED NAMESPACE
#+name:NAMESPACE
#+begin_src txt :tangle no :exports reports :eval no :padline
exportPattern("^[[:alpha:]]+")
#+end_src
** DEPRECATED DESCRIPTION
*** COMMENT DESCRIPTION-code
#+name:DESCRIPTION
#+begin_src R :session *R* :tangle no :exports none :eval no :padline no
  Package: HutchinsonDroughtIndex
  Type: Package
  Title: Hutchinson's Drought Index
  Version: 1.1
  Date: 2015-11-06
  Author: ivanhanigan, lucianaporforio, Michael Hutchinson
  Maintainer: <ivan.hanigan@gmail.com>
  Depends:
      raster,
      rgdal,
      zoo
  Description: drought function
  License: GPL (>= 2)
  Collate:
      'drought_index_future.r'
      'drought_index_grids.r'
      'drought_index_stations.r'
#+end_src

* Functions
** drought_index_stations
*** R-drought_index_stations
#+name:drought_index_stations
#+begin_src R :session *R* :tangle R/drought_index_stations.r :exports none :eval no :padline no
  #' @name drought_index_stations
  #' @title Drought Index For Stations
  #' @param data a dataframe with date, year month and rain
  #' @param years the number of years in the time series
  #' @param M number of months in rolling sum, default 6
  #' @param droughtThreshold the level of dryness below which a drought begins
  #' @return dataframe with droughtIndices
  #' @export
  #'
  drought_index_stations<-function(data,years,M=6,droughtThreshold=.375){
  # a drought index based on integrated six-monthly rainfall percentiles.
  # based on Professor Mike Hutchinson's work described in 
  # Smith D, Hutchinson M, McArthur R. Climatic and Agricultural Drought: Payments and Policy. 
  # Canberra, ACT: Centre for Resource and Environmental Studies, Australian National University. 1992.  
  
  # Ivan C Hanigan
  # June 2011.
    
  ################################################################################
  ## Copyright 2011, Ivan C Hanigan <ivan.hanigan@gmail.com> and Michael F Hutchinson
  ## This program is free software; you can redistribute it and/or modify
  ## it under the terms of the GNU General Public License as published by
  ## the Free Software Foundation; either version 2 of the License, or
  ## (at your option) any later version.
  ## 
  ## This program is distributed in the hope that it will be useful,
  ## but WITHOUT ANY WARRANTY; without even the implied warranty of
  ## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  ## GNU General Public License for more details.
  ## Free Software
  ## Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
  ## 02110-1301, USA
  ################################################################################
  
  
  # my input data are always a data.frame with 4 columns 'date','year','month','rain'
   
  #calculate M month totals
  # started with 6 (current and prior months)
  x <- ts(data[,4],start=1,end=c(years,12),frequency=12)
  x <- zoo::rollapplyr(x, width = M, FUN = sum, fill = NA)
  data$sixmnthtot<-x
  data<-na.omit(data)
  
  # rank in percentage terms with respect to the rainfall totals 
  # for the same sequence of 6-months over all years of record
  dataout_final=matrix(nrow=0,ncol=7)
  
  for(i in 1:12){
          x<-data[data$month==i,5]
          #x<-na.omit(x)
          y<-(rank(x)-1)/(length(x)-1)
          # checkpct<-cbind(data[data$month==i,],y)
          # plot(checkpct$sixmnthtot,checkpct$y)
          # rescale between -4 and +4 to replicate palmer index 
          z<-8*(y-.5)
          # defualts set the threshold at -1 which is upper limit of
          # mild drought in palmer index
          # (3/8ths, or the 37.5th percentile) 
          drought<-x<=quantile(x,droughtThreshold)
          # calculate the drought index for any months that fall below the threshold
          zd<-z*drought
          # save out to the data
          dataout<-data[data$month==i,]
          dataout$index<-z
          dataout$indexBelowThreshold<-zd
          dataout_final=rbind(dataout_final,dataout)
          }
                  
  data<-dataout_final[order(dataout_final$date),]
  
  # now calculate the indices
  # newnode COUNTS
  data$count<-as.numeric(0)
  # OLD and SLOW
  # for(j in 2:nrow(data)){
          # data$count[j]<-ifelse(data$indexBelowThreshold[j]==0,0,
          # ifelse(data$indexBelowThreshold[j-1]!=0,1+data$count[j-1],
          # 1)
          # )
          # }
  
  # NEW and FAST
  # counts can be done with this funky bit of code 
  x<-data$index<=-1
  xx <- (cumsum(!x) + 1) * x 
  x2<-(seq_along(x) - match(xx, xx) + 1) * x 
  data$count<-x2
  
  # OLD and SLOW enhanced drought revocation threshold 
  # TASK make NEW and FAST? or add as an option?
  # In the enhanced version rather than stop counting when the rescaled percentiles rise above -1.0, 
  # we keep counting the months (or adding the negative anomalies) 
  # if the rescaled percentile is below 0.0 AND the drought threshold has already been reached. 
  # If the threshold has not been reached, then stop counting (or adding) as before 
  # if the rescaled percentile rises above -1.0.
  
  data$count2<-data$count
  # j=1080 # 1980-06
  # data[j,]
  
  for(j in 2:nrow(data)){ 
  data$count2[j] <- if(data$count2[j-1] >= 5 & data$index[j] <= 0){
          data$count2[j-1] + 1
          } else {                
          # ifelse(data$count[j-1] > 0 & data$index[j] < 0, 1+data$count[j-1],
          data$count2[j]
          }
  }
  ############################################################
  # newnode SUMS
  # NEW and FAST? or add as an option?
  data$sums<-as.numeric(0)
  y <- ifelse(data$index >= -1, 0, data$index)
  f <- data$index < -1
  f <- (cumsum(!f) + 1) * f 
  z <- unsplit(lapply(split(y,f),cumsum),f)
  data$sums <- z
  # OLD and SLOW
  # for(j in 2:nrow(data)){
          # data$sums[j]<-ifelse(data$indexBelowThreshold[j]==0,0,
          # ifelse(data$indexBelowThreshold[j-1]!=0,
          # data$indexBelowThreshold[j]+data$sums[j-1],
          # data$indexBelowThreshold[j]))
          # }
          
  # OLD and SLOW
  # TASK make NEW and FAST
  data$sums2<-data$sums
  # j=1069 # 1980-06
  # data[j,]
  
  for(j in 2:nrow(data)){ 
  data$sums2[j] <- if(data$sums2[j-1] <= -17.5 & data$index[j] <= 0){
          data$sums2[j-1] + data$index[j]
          } else {                
          # ifelse(data$count[j-1] > 0 & data$index[j] < 0, 1+data$count[j-1],
          data$sums2[j]
          }
  }
  
  droughtIndices<-data
  return(droughtIndices)
  }
  
  
  
#+end_src
*** test-drought_index_stations
#+name:drought_index_stations
#+begin_src R :session *R* :tangle tests/test-drought_index_stations.r :exports none :eval no 
  ################################################################
  # name:drought_index_stations
  analyte <- read.table("~/projects/HutchinsonDroughtIndex/inst/extdata/prcphq.046037.month.txt", quote="\"", skip = 1, nrows = 1440)
  
  # clean
  str(analyte)
  head(analyte);tail(analyte)
  
  analyte <- data.frame(analyte[,1], substr(analyte[,1], 1,4) , substr(analyte[,1],5,6), analyte[,3])
  names(analyte) <- c('date',  'year' , 'month' ,'rain')
  str(analyte)
  analyte$year <- as.numeric(as.character(analyte$year))
  analyte$month <- as.numeric(as.character(analyte$month))
  str(analyte)
  subset(data.frame(table(na.omit(analyte)[,"year"])), Freq < 12)
  # are all months present?
  
  # do
  drt <- drought_index_stations(data=analyte,years=length(names(table(analyte$year))),droughtThreshold=.375)
  
  # report
  summary(drt)
  with(drt, plot(as.Date(date), count, "l"))
  abline(5,0)
  par(new=T)
  with(drt, plot(as.Date(date), -1*sums, col= "red", type="l"))
  
#+end_src
*** man-drought_index_stations
#+name:drought_index_stations
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:drought_index_stations

#+end_src

** drought_index_grids
*** R-drought_index_grids
# name:drought_index_grids

## TODO-list: 
# count2 and sums, convert matrices to bricks.
# set it up to work on subsets of the grid and put them back together after

#+name:drought_index_grids
#+begin_src R :session *R* :tangle R/drought_index_grids.r :exports none :eval no :padline no
  #' @name drought_index_grids
  #' @title drought index using grids
  #' @param rasterbrick a stack of grids
  #' @param startyear the start year
  #' @param endyear the end year
  #' @param droughtThreshold the level of dryness
  #' @return dataframe with droughtIndices
  #' @export
  #'
  drought_index_grids <- function(rasterbrick,startyear,endyear,droughtThreshold=.375){
      
    b<-getValuesBlock(rasterbrick, row=500, nrows=5, col=500, ncols=5)
    # TODO estimate the max and min date from the data filenames
    x<-apply(b, 1, function(x) ts(x,start=c(startyear, 01),end=c(endyear,12),frequency=12))
    sixmnthtot<-apply(x, 2, function(x) c(rep(NA,5),x+lag(x,1)+lag(x,2)+lag(x,3)+lag(x,4)+lag(x,5)))
    # TODO it might be faster to use zoo::rollapply,
    # and also we can make the lag length variable
     
    ##rank
    # TODO select for each month ie all Januarys are ranked seperate from Febs etc
    rank <- apply(x, 2, function(x) {return((rank(x)-1)/(length(x)-1))})
    index <- apply(rank, 2, function(x) 8*(x-.5)) #to be a brick
    # .375 is refering to palmer's benchmark but we could let the user vary this
    drought <- apply(x, 2, function(x) x<=quantile(x,droughtThreshold)) 
    indexBelowThreshold <- index*drought #to be a  brick
     
    ##count
    x1 <- index<=-1
    x2 <- apply(x1, 2, function(x) (cumsum(!x) + 1) * x )
    seq <- apply(x1, 2, function(x) seq_along(x))
    match <- apply(x2, 2, function(x) match(x,x))
    count<- (seq - match + 1) * x1 #double check #to be a brick
    return(count)
  }
  
#+end_src
*** test-drought_index_grids
#+name:drought_index_grids
#+begin_src R :session *R* :tangle tests/test-drought_index_grids.r :exports none :eval no
################################################################
# name:drought_index_grids
if(!require(devtools)) install.packages("devtools", depend = T); require(devtools)
install_github("HutchinsonDroughtIndex", "ivanhanigan")
require(HutchinsonDroughtIndex)
wd <- getwd()
setwd("~/data/AWAP_GRIDS/data")
##Lu 13-14 Jan 2014
require(raster); require(rgdal)
##path?
awap.grids = dir(pattern = "grid$", full.names=T)
#  list.files('AWAP_GRIDS', pattern=glob2rx('totals*.grid'), full.names=T)
for(i in 1:12){
  #i = 1
  #file.copy(awap.grids[i], sprintf("foo%s.grid", i))}
  r <- raster(awap.grids[i])
  #str(r)
  #image(r)
  fname <- gsub(".grid",".tif", awap.grids[i])
  # TODO project this please lu!
  writeRaster(r, filename= fname, type = "GTiff")
  #file.remove(awap.grids[i])
}
## for some reason brick or stack only don't work, both together do
awap.grids <- dir(pattern = 'tif')[1:12]
rb <- brick(stack(awap.grids)) #takes too l

## I'm not sure what's more efficient, if changing the drought function 
## to do the cal on matrices or just running the function on the vectors

##option 1 modif function
ct <- drought_index_grids(rasterbrick = rb,startyear = 1900, endyear=1900, droughtThreshold=.375)
plot(ct[,1], type = "l")

#+end_src
*** man-drought_index_grids
#+name:drought_index_grids
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:drought_index_grids

#+end_src

** drought_index_future
*** R-drought_index_future
#+begin_src R :session *R* :tangle R/drought_index_future.r :exports none :eval no :padline no
  #' @name drought_index_future
  #' @title Drought Index For Stations for future projected rainfall
  #' @param data a dataframe with date , year, month, rain
  #' @param years the number of years in the time series
  #' @param M number of months in rolling sum, default 6
  #' @param droughtThreshold the level of dryness below which a drought begins
  #' @return dataframe with droughtIndices
  #' @export
  #'
  drought_index_future <- function(data,years,baseline,M=6,droughtThreshold=.375){
  # a drought index based on integrated six-monthly rainfall percentiles.
  # based on Professor Mike Hutchinson's work described in
  # Smith D, Hutchinson M, McArthur R. Climatic and Agricultural Drought: Payments and Policy.
  # Canberra, ACT: Centre for Resource and Environmental Studies, Australian National University. 1992.
  
  # Ivan C Hanigan
  # June 2011.
    
  ################################################################################
  ## Copyright 2011, Ivan C Hanigan <ivan.hanigan@gmail.com> and Michael F Hutchinson
  ## This program is free software; you can redistribute it and/or modify
  ## it under the terms of the GNU General Public License as published by
  ## the Free Software Foundation; either version 2 of the License, or
  ## (at your option) any later version.
  ## 
  ## This program is distributed in the hope that it will be useful,
  ## but WITHOUT ANY WARRANTY; without even the implied warranty of
  ## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  ## GNU General Public License for more details.
  ## Free Software
  ## Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
  ## 02110-1301, USA
  ################################################################################
  
  
  # my input data are always a data.frame with 4 columns
  # 'date','year','month','rain'
  # we want to only use the baseline to get our percentile values  
  data_baseline <- data[data$year >= min(baseline) & data$year <= max(baseline),]
  #summary(data_baseline)
  nyears <- length(names(table(data_baseline$year)))
  #calculate M month totals
  x <- ts(data_baseline[,4],start=1,end=c(nyears,12),frequency=12)
  x <- zoo::rollapplyr(x, width = M, FUN = sum, fill = NA)
  data_baseline$sixmnthtot <- x
  data_baseline <- na.omit(data_baseline)
  
  nyears2 <- length(names(table(data$year)))
  x2<-ts(data[,4],start=1,end=c(nyears2,12),frequency=12)
  x2<-c(rep(NA,5),x2+lag(x2,1)+lag(x2,2)+lag(x2,3)+lag(x2,4)+lag(x2,5))
  # TASK need to use rollapply?
  data$sixmnthtot <- x2
  data <- na.omit(data)
  
  
  
  # now rank in percentage terms with respect to the rainfall totals 
  # for the same sequence of 6-months over all years of record
  dataout_final=matrix(nrow=0,ncol=7)
  
  for(i in 1:12){
  #  i = 1
          x<-data_baseline[data_baseline$month==i,"sixmnthtot"]
          x2<-data[data$month==i,"sixmnthtot"]
          #x<-na.omit(x)
          # TODO but this is the distribution of the entire series, in and out of the baseline
          y<-(rank(x2)-1)/(length(x2)-1)
          # checkpct<-cbind(data[data$month==i,],y)
          # plot(checkpct$sixmnthtot,checkpct$y)
          # rescale between -4 and +4 to replicate palmer index 
          z<-8*(y-.5)
          # defualts set the threshold at -1 which is upper limit of
          # mild drought in palmer index
          # (3/8ths, or the 37.5th percentile) OF THE BASELINE X
          # TODO so the threshold is on the baseline, but the x2 series is everything
          drought <- x2 <= quantile(x,droughtThreshold)
          # calculate the drought index for any months that fall below the threshold
          # TODO but z is on whole series, but drought is based on exceeding the baseline threshold?
          zd<-z*drought
          # save out to the data
          dataout<-data[data$month==i,]
          dataout$index<-z
          dataout$indexBelowThreshold<-zd
          dataout_final=rbind(dataout_final,dataout)
          }
                  
  data<-dataout_final[order(dataout_final$date),]
  
  # now calculate the indices
  # newnode COUNTS
  data$count<-as.numeric(0)
  # OLD and SLOW
  # for(j in 2:nrow(data)){
          # data$count[j]<-ifelse(data$indexBelowThreshold[j]==0,0,
          # ifelse(data$indexBelowThreshold[j-1]!=0,1+data$count[j-1],
          # 1)
          # )
          # }
  
  # NEW and FAST
  # counts can be done with this funky bit of code 
  x<-data$index<=-1
  xx <- (cumsum(!x) + 1) * x 
  x2<-(seq_along(x) - match(xx, xx) + 1) * x 
  data$count<-x2
  
  # OLD and SLOW enhanced drought revocation threshold 
  # TASK make NEW and FAST? or add as an option?
  # In the enhanced version rather than stop counting when the rescaled percentiles rise above -1.0, 
  # we keep counting the months (or adding the negative anomalies) 
  # if the rescaled percentile is below 0.0 AND the drought threshold has already been reached. 
  # If the threshold has not been reached, then stop counting (or adding) as before 
  # if the rescaled percentile rises above -1.0.
  
  data$count2<-data$count
  # j=1080 # 1980-06
  # data[j,]
  
  for(j in 2:nrow(data)){ 
  data$count2[j] <- if(data$count2[j-1] >= 5 & data$index[j] <= 0){
          data$count2[j-1] + 1
          } else {                
          # ifelse(data$count[j-1] > 0 & data$index[j] < 0, 1+data$count[j-1],
          data$count2[j]
          }
  }
  ############################################################
  # newnode SUMS
  # NEW and FAST? or add as an option?
  data$sums<-as.numeric(0)
  y <- ifelse(data$index >= -1, 0, data$index)
  f <- data$index < -1
  f <- (cumsum(!f) + 1) * f 
  z <- unsplit(lapply(split(y,f),cumsum),f)
  data$sums <- z
  # OLD and SLOW
  # for(j in 2:nrow(data)){
          # data$sums[j]<-ifelse(data$indexBelowThreshold[j]==0,0,
          # ifelse(data$indexBelowThreshold[j-1]!=0,
          # data$indexBelowThreshold[j]+data$sums[j-1],
          # data$indexBelowThreshold[j]))
          # }
          
  # OLD and SLOW
  # TASK make NEW and FAST
  data$sums2<-data$sums
  # j=1069 # 1980-06
  # data[j,]
  
  for(j in 2:nrow(data)){ 
  data$sums2[j] <- if(data$sums2[j-1] <= -17.5 & data$index[j] <= 0){
          data$sums2[j-1] + data$index[j]
          } else {                
          # ifelse(data$count[j-1] > 0 & data$index[j] < 0, 1+data$count[j-1],
          data$sums2[j]
          }
  }
  
  droughtIndices<-data
  return(droughtIndices)
  }
  
#+end_src

*** test-drought_index_future

#+name:drought_index_future
#+begin_src R :session *R* :tangle tests/test-drought_index_future.r :exports none :eval no
  ################################################################
  # name:drought_index_stations
  # for info see
  # https://github.com/ivanhanigan/GARNAUT_CLIMATE_CHANGE_REVIEW
  # drought futures sub project
  
  ## dat <- read.csv("~/projects/GARNAUT_CLIMATE_CHANGE_REVIEW/drought_futures/data/rain_future_estimated_dry.csv", stringsAsFactors = F)
  
  ## names(dat)
  ## head(dat)
  ## tail(dat)
  ## dat$date <- as.Date(paste(dat$year, dat$month, 1, sep = "-"))
  
  ## sds <- names(table(dat$sd_group))
  ## sds
  
  ## # save a test dataset for developing the fucntion with, transfer to
  ## # hutch package
  ## sd_i <- c("Central West", "Murrumbidgee")
  ## dat2 <- dat[dat$year > 1890 & dat$sd_group %in% sd_i, c('sd_group','date','year','month','avrain')]
  ## summary(dat2)
  ## table(dat2$sd_group)
  ## head(dat2, 24)
  ## par(mfrow = c(2,1))
  ## for(sdi in sd_i){
  ##   with(dat2[dat2$sd_group == sdi,],
  ##        plot(date, avrain, type = "l")
  ##        )
  ##   title(sdi)
  ## }
  ## write.csv(dat2, "~/projects/HutchinsonDroughtIndex/inst/extdata/GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv", row.names = F)
  
  library(HutchinsonDroughtIndex)
  
  analyte <- read.csv("~/projects/HutchinsonDroughtIndex/inst/extdata/GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv")
  
  # clean
  str(analyte)
  head(analyte);tail(analyte)
  
  analyte  <- analyte[analyte$sd_group == "Murrumbidgee", c("date", "year", "month","avrain")]
  
  # do
  ## drt <- drought_index_future(
  ##   data=analyte
  ##   ,
  ##   baseline = c(1891, 2008)
  ##   ,
  ##   years=length(names(table(analyte$year)))
  ##   ,
  ##   droughtThreshold=.375
  ##   )
  
  ## # report
  ## par(mfrow = c(2,1))
  ## summary(drt)
  ## with(drt[drt$year > 1980 & drt$year <2010,], plot(as.Date(date), count, "l"))
  ## abline(5,0)
  
  analyte2 <- analyte[analyte$year < 2009,]
  drt2 <- drought_index_stations(
    data=analyte2
    ,
    years=length(names(table(analyte2$year)))
    ,
    droughtThreshold=.375
    )
  with(drt2[drt2$year > 1980 & drt2$year <2010,], plot(as.Date(date), count, "l"))
  abline(5,0)
  
  dev.off()
  #par(new=T)
  #with(drt, plot(as.Date(date), -1*sums, col= "red", type="l"))
  
  
  
  
#+end_src

*** COMMENT scratch
#+name:scratch
#+begin_src R :session *R* :tangle scratch.R :exports none :eval no
#### name:scratch ####
x<-ts(data_baseline[,4],start=1,end=c(nyears,12),frequency=12)
x3<-c(rep(NA,5),x+lag(x,1)+lag(x,2)+lag(x,3)+lag(x,4)+lag(x,5))
library(zoo)
x2 <- x
?rollapply
M=6
qc <- data.frame(x2, rollapplyr(x2, width = M, FUN = sum, fill = NA), x3)
plot(qc[,2], qc[,3])

#+end_src

* Vignettes
** COMMENT DEPRECATED HutchinsonDroughtIndex-code
#+begin_src tex :tangle no :eval no :padline no
\documentclass{article}
%\VignetteIndexEntry{HutchinsonDroughtIndex}
\begin{document}
\SweaveOpts{concordance=TRUE}
\begin{center}
\Large
{\tt HutchinsonDroughtIndex} Package Vignette
\normalsize
\end{center}
The following figure illustrates a sequence of numbers.
<<keep.source=TRUE>>=
library('HutchinsonDroughtIndex')
x <- rnorm(100,1,2)
x
@
\end{document}
#+end_src
** COMMENT vig
#+name:vig
#+begin_src R :session *R* :tangle no :exports none :eval yes
  #### name:vig ####
  setwd("~/projects/HutchinsonDroughtIndex/vignettes")
  library(knitr)
  #dir()
  rmarkdown::render("HutchinsonDroughtIndex.Rmd")
  browseURL("HutchinsonDroughtIndex.html")
#+end_src

#+RESULTS: vig
: 0

*** COMMENT head
#+begin_src R :session *R* :tangle vignettes/HutchinsonDroughtIndex.Rmd :exports none :eval no :padline
---
title: "Hutchinson Drought Index"
author: "Ivan Hanigan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Hutchinson Drought Index}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
#+end_src
*** COMMENT intro
#+begin_src R :session *R* :tangle vignettes/HutchinsonDroughtIndex.Rmd :exports none :eval no :padline

# Introduction

This is a short introduction to the algorithm.  For fuller explanation see the original chapter of the report, included in the documentation of this package.

#+end_src
*** COMMENT show central west
**** scratch
#+name:scratch
#+begin_src R :session *R* :tangle scratch.R :exports none :eval no
  #### name:scratch ####
  dat <- read.csv("~/projects/HutchinsonDroughtIndex/inst/extdata/GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv")
  
  # better just check that these data are the same as the rainfall I had
  # for the suicide paper
  qc1 <- subset(dat, year <= 2007)
  indir <- "~/Private/SuicideAndDroughtInNSW"
  dir(indir)
  infile <- "suicidedroughtnsw19702007_rates_drought.csv"
  qc2 <- read.csv(file.path(indir, infile))
  names(qc2)
  summary(qc2)
  qc2 <- subset(qc2, sex == "1" & agegp == "30_39")
  qc3 <- merge(qc1, qc2, by.x = c("sd_group", "year", "month"), by.y = c("sd_group", "dthyy", "dthmm"))
  with(qc3, plot(avrain.x, avrain.y))
  abline(0,1)
  # great
  
#+end_src

**** good
#+begin_src R :session *R* :tangle vignettes/HutchinsonDroughtIndex.Rmd :exports none :eval no :padline
  # The southwest slopes and plains region of New South Wales
  
  - The southwest slopes and plains are included as a case study
  - Data from the Garnaut Climate Change Review are provided
  - These apply the future scenarios to the century and assumes that the rainfall pattern will be a repeat with the new conditions  
  - This is obviously too simplistic, but was the method applied in our work in 2008 and of historical interest  
  
  ```{r, eval = F, echo = T}
  library(HutchinsonDroughtIndex)
  projdir <- "~/projects/HutchinsonDroughtIndex/vignettes"
  setwd(projdir)
  indir <- file.path(system.file(package="HutchinsonDroughtIndex"), "extdata")
  dir(indir)
  infile <- "GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv"
  dat <- read.csv(file.path(indir, infile))
  str(dat)
  dat$date <- as.Date(dat$date)
  sds <- names(table(dat$sd_group))
  png("graphs/rainfall_from_garnaut_review.png")
  par(mfrow = c(2,1))
  for(sdi in sds){
  with(dat[dat$sd_group == sdi,],
    plot(date, avrain, type = "l", col = "grey")
  )
  with(dat[dat$sd_group == sdi,],
    lines(lowess(avrain ~ date, f = 0.02),  col = "blue")
  )
    title(sdi)
  }
  dev.off()
  ```
  
  ![graphs/rainfall_from_garnaut_review.png](graphs/rainfall_from_garnaut_review.png)
  
#+end_src
*** show original method
#+begin_src R :session *R* :tangle vignettes/HutchinsonDroughtIndex.Rmd :exports none :eval no :padline
  # Hutchinsons indices based on entire historical distribution
  
  - The method was first made available as a simple algorithm that looks at the entire distribution of the time series
  
  ```{r, eval = F, echo = T}
  # just use the observed record
  dat2 <- subset(dat, year <= 2007)
  tail(dat2)
  # the function runs on one region only
  #for(sdi in sds){
  sdi <- sds[2]
    indat <- subset(dat2, sd_group == sdi, select = c("date", "year", "month", "avrain"))
    drt <- drought_index_stations(indat, years = length(names(table(indat$year))), M = 6)
  str(drt)
  #}
  
  # when is there an example of the enhancement making a drought longer?
  tail(drt[drt$sums2!=drt$sums,])
  # plot this one
  qc3=drt[drt$year>=1999,]
  
  png(file.path("graphs", sprintf("%sDroughtEnhanced.png",sdi)), res=200, width = 2100, height = 1000)
  par(mfrow=c(4,1),mar=c(2.5,2,1.5,1))
  plot(qc3$date,qc3$avrain,type='l',main=sprintf('%s: raw monthly rainfall', sdi))
  #points(qc3$date,qc3$avrain)
  axis(1,at=as.Date(paste(1994:1998,1,1,sep='-')), labels = 1994:1998)
  lines(qc3$date,qc3$sixmnthtot/6, lwd = 2) #,type='l',main='6-monthly total rainfall')
  points(qc3$date,qc3$sixmnthtot/6)
  axis(1,at=as.Date(paste(1994:1998,1,1,sep='-')), labels = 1994:1998)
  plot(qc3$date,qc3$index,type='l',main='rescaled percentiles -4 to +4, -1 is Palmer Index Mild Drought',ylim=c(-4,4))
  points(qc3$date,qc3$index)
  segments(min(qc3$date),-1,max(qc3$date),-1)
  segments(min(qc3$date),0,max(qc3$date),0,lty=2)
  plot(qc3$date,qc3$sums,type='l',main='sums below -1 threshold, sums of -17.5 or less is a drought')
  points(qc3$date,qc3$sums)
  segments(min(qc3$date),-17.5,max(qc3$date),-17.5)
  axis(1,at=as.Date(paste(1994:1998,1,1,sep='-')), labels = 1994:1998)
  plot(qc3$date,qc3$sums2,type='l',main='enhanced sums of months if already passed threshold of -17.5 and percentiles less than 50%')
  points(qc3$date,qc3$sums2)
  segments(min(qc3$date),-17.5,max(qc3$date),-17.5)
  axis(1,at=as.Date(paste(1994:1998,1,1,sep='-')), labels = 1994:1998)
  dev.off()
  
  ```
  
  ![graphs/MurrumbidgeeDroughtEnhanced.png](graphs/MurrumbidgeeDroughtEnhanced.png)
  
  
#+end_src
* Worklog
** 2015-11-08 results from Ivan Re: build test dataset for NSW SDs using AWAP historic + CSIRO future
- aim is to average gridded awap data on nswsd07, just like the garnaut stuff

# 8th november preparatory work

## awap
- AWAP is good updating whereas emast is now stopped
-  A script is to download the spatial grids of the Australian Water Availability Project
- http://www.bom.gov.au/jsp/awap/
- https://github.com/swish-climate-impact-assessment/AWAP_GRIDS

## access
- Australian Community Climate and Earth System Simulator (ACCESS) is good future 
- http://www.csiro.au/en/Research/OandA/Areas/Assessing-our-climate/CAWCR/ACCESS

# 9th Nov 
- prepping for Lu to help
- downloaded all awap data again on swish-R
- extract the vals for the NSWSD11, and NSW DPI PPD
- calc drought with latest function
