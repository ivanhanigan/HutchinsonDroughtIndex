#+TITLE:HutchinsonDroughtIndex 
#+AUTHOR: Ivan Hanigan
#+email: ivan.hanigan@anu.edu.au
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [a4paper]
#+LATEX: \tableofcontents
-----
* TODO-list
** news story
- http://mobile.abc.net.au/news/2015-07-06/drought-worries-rising-victoria-south-australia-rainfall-lowest/6597870
** do PPD
NSW DPI PPD (that will feed into the calibration paper)
** build
devtools::build()
  ‘HutchinsonDroughtIndex/inst/extdata/GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv’

[1] "/home/ivan_hanigan/projects/HutchinsonDroughtIndex_1.1.tar.gz"
> install.packages("~/projects/HutchinsonDroughtIndex_1.1.tar.gz", repos = NULL, type = "source")
rm these after as clutter
* Introduction

** package doc
#+name:swishdbtools-package
#+begin_src R :session *R* :tangle man/HutchinsonDroughtIndex-package.Rd :exports none :eval no
  \name{HutchinsonDroughtIndex-package}
  \alias{HutchinsonDroughtIndex-package}
  \alias{HutchinsonDroughtIndex}
  \docType{package}
  \title{
  Hutchinson Drought Index
  }
  \description{
  Climatic Drought
  }
  \details{
  \tabular{ll}{
  Package: \tab HutchinsonDroughtIndex\cr
  Type: \tab Package\cr
  Version: \tab 1.1\cr
  Date: \tab 2015-11-06\cr
  License: \tab GPL2\cr
  }
  The package is designed to take a timeseries for a single location such as region or weather station and compute the drought index.  Dev work on grid version.
  }
  \author{
  
  
  Maintainer: <ivan.hanigan@gmail.com>
  
  }
  \references{
  
  Smith, D. I, Hutchinson, M. F, & McArthur, R. J. (1992) Climatic and
  Agricultural Drought: Payments and Policy. (Centre for Resource and
  Environmental Studies, Australian National University, Canberra,
  Australia). http://fennerschool-research.anu.edu.au/spatio-temporal/publications/cres_paper1992.pdf
  
  Hanigan, IC. 2012. The Hutchinson Drought Index Algorithm [Computer
  Software].  https://github.com/ivanhanigan/HutchinsonDroughtIndex
  
  }
  
#+end_src

** run tests
#+name:test_project
#+begin_src R :session *R* :tangle test_project.r :exports none :eval no
  ################################################################
  # name:test_project
  require(testthat)
  test_dir('tests')
  
#+end_src

** DEPRECATED NAMESPACE
#+name:NAMESPACE
#+begin_src txt :tangle no :exports reports :eval no :padline
exportPattern("^[[:alpha:]]+")
#+end_src
** DEPRECATED DESCRIPTION
*** COMMENT DESCRIPTION-code
#+name:DESCRIPTION
#+begin_src R :session *R* :tangle no :exports none :eval no :padline no
  Package: HutchinsonDroughtIndex
  Type: Package
  Title: Hutchinson's Drought Index
  Version: 1.1
  Date: 2015-11-06
  Author: ivanhanigan, lucianaporforio, Michael Hutchinson
  Maintainer: <ivan.hanigan@gmail.com>
  Depends:
      raster,
      rgdal,
      zoo
  Description: drought function
  License: GPL (>= 2)
  Collate:
      'drought_index_future.r'
      'drought_index_grids.r'
      'drought_index_stations.r'
#+end_src

* Functions
** drought_index_stations
*** R-drought_index_stations
#+name:drought_index_stations
#+begin_src R :session *R* :tangle R/drought_index_stations.r :exports none :eval no :padline no
  #' @name drought_index_stations
  #' @title Drought Index For Stations
  #' @param data a dataframe with date, year month and rain
  #' @param years the number of years in the time series
  #' @param M number of months in rolling sum, default 6
  #' @param droughtThreshold the level of dryness below which a drought begins
  #' @return dataframe with droughtIndices
  #' @export
  #'
  drought_index_stations<-function(data,years,M=6,droughtThreshold=.375){
  # a drought index based on integrated six-monthly rainfall percentiles.
  # based on Professor Mike Hutchinson's work described in 
  # Smith D, Hutchinson M, McArthur R. Climatic and Agricultural Drought: Payments and Policy. 
  # Canberra, ACT: Centre for Resource and Environmental Studies, Australian National University. 1992.  
  
  # Ivan C Hanigan
  # June 2011.
    
  ################################################################################
  ## Copyright 2011, Ivan C Hanigan <ivan.hanigan@gmail.com> and Michael F Hutchinson
  ## This program is free software; you can redistribute it and/or modify
  ## it under the terms of the GNU General Public License as published by
  ## the Free Software Foundation; either version 2 of the License, or
  ## (at your option) any later version.
  ## 
  ## This program is distributed in the hope that it will be useful,
  ## but WITHOUT ANY WARRANTY; without even the implied warranty of
  ## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  ## GNU General Public License for more details.
  ## Free Software
  ## Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
  ## 02110-1301, USA
  ################################################################################
  
  
  # my input data are always a data.frame with 4 columns 'date','year','month','rain'
   
  #calculate M month totals
  # started with 6 (current and prior months)
  x <- ts(data[,4],start=1,end=c(years,12),frequency=12)
  x <- zoo::rollapplyr(x, width = M, FUN = sum, fill = NA)
  data$sixmnthtot<-x
  data<-na.omit(data)
  
  # rank in percentage terms with respect to the rainfall totals 
  # for the same sequence of 6-months over all years of record
  dataout_final=matrix(nrow=0,ncol=7)
  
  for(i in 1:12){
          x<-data[data$month==i,5]
          #x<-na.omit(x)
          y<-(rank(x)-1)/(length(x)-1)
          # checkpct<-cbind(data[data$month==i,],y)
          # plot(checkpct$sixmnthtot,checkpct$y)
          # rescale between -4 and +4 to replicate palmer index 
          z<-8*(y-.5)
          # defualts set the threshold at -1 which is upper limit of
          # mild drought in palmer index
          # (3/8ths, or the 37.5th percentile) 
          drought<-x<=quantile(x,droughtThreshold)
          # calculate the drought index for any months that fall below the threshold
          zd<-z*drought
          # save out to the data
          dataout<-data[data$month==i,]
          dataout$index<-z
          dataout$indexBelowThreshold<-zd
          dataout_final=rbind(dataout_final,dataout)
          }
                  
  data<-dataout_final[order(dataout_final$date),]
  
  # now calculate the indices
  # newnode COUNTS
  data$count<-as.numeric(0)
  # OLD and SLOW
  # for(j in 2:nrow(data)){
          # data$count[j]<-ifelse(data$indexBelowThreshold[j]==0,0,
          # ifelse(data$indexBelowThreshold[j-1]!=0,1+data$count[j-1],
          # 1)
          # )
          # }
  
  # NEW and FAST
  # counts can be done with this funky bit of code 
  x<-data$index<=-1
  xx <- (cumsum(!x) + 1) * x 
  x2<-(seq_along(x) - match(xx, xx) + 1) * x 
  data$count<-x2
  
  # OLD and SLOW enhanced drought revocation threshold 
  # TASK make NEW and FAST? or add as an option?
  # In the enhanced version rather than stop counting when the rescaled percentiles rise above -1.0, 
  # we keep counting the months (or adding the negative anomalies) 
  # if the rescaled percentile is below 0.0 AND the drought threshold has already been reached. 
  # If the threshold has not been reached, then stop counting (or adding) as before 
  # if the rescaled percentile rises above -1.0.
  
  data$count2<-data$count
  # j=1080 # 1980-06
  # data[j,]
  
  for(j in 2:nrow(data)){ 
  data$count2[j] <- if(data$count2[j-1] >= 5 & data$index[j] <= 0){
          data$count2[j-1] + 1
          } else {                
          # ifelse(data$count[j-1] > 0 & data$index[j] < 0, 1+data$count[j-1],
          data$count2[j]
          }
  }
  ############################################################
  # newnode SUMS
  # NEW and FAST? or add as an option?
  data$sums<-as.numeric(0)
  y <- ifelse(data$index >= -1, 0, data$index)
  f <- data$index < -1
  f <- (cumsum(!f) + 1) * f 
  z <- unsplit(lapply(split(y,f),cumsum),f)
  data$sums <- z
  # OLD and SLOW
  # for(j in 2:nrow(data)){
          # data$sums[j]<-ifelse(data$indexBelowThreshold[j]==0,0,
          # ifelse(data$indexBelowThreshold[j-1]!=0,
          # data$indexBelowThreshold[j]+data$sums[j-1],
          # data$indexBelowThreshold[j]))
          # }
          
  # OLD and SLOW
  # TASK make NEW and FAST
  data$sums2<-data$sums
  # j=1069 # 1980-06
  # data[j,]
  
  for(j in 2:nrow(data)){ 
  data$sums2[j] <- if(data$sums2[j-1] <= -17.5 & data$index[j] <= 0){
          data$sums2[j-1] + data$index[j]
          } else {                
          # ifelse(data$count[j-1] > 0 & data$index[j] < 0, 1+data$count[j-1],
          data$sums2[j]
          }
  }
  
  droughtIndices<-data
  return(droughtIndices)
  }
  
  
  
#+end_src
*** test-drought_index_stations
#+name:drought_index_stations
#+begin_src R :session *R* :tangle tests/test-drought_index_stations.r :exports none :eval no 
  ################################################################
  # name:drought_index_stations
  analyte <- read.table("~/projects/HutchinsonDroughtIndex/inst/extdata/prcphq.046037.month.txt", quote="\"", skip = 1, nrows = 1440)
  
  # clean
  str(analyte)
  head(analyte);tail(analyte)
  
  analyte <- data.frame(analyte[,1], substr(analyte[,1], 1,4) , substr(analyte[,1],5,6), analyte[,3])
  names(analyte) <- c('date',  'year' , 'month' ,'rain')
  str(analyte)
  analyte$year <- as.numeric(as.character(analyte$year))
  analyte$month <- as.numeric(as.character(analyte$month))
  str(analyte)
  subset(data.frame(table(na.omit(analyte)[,"year"])), Freq < 12)
  # are all months present?
  
  # do
  drt <- drought_index_stations(data=analyte,years=length(names(table(analyte$year))),droughtThreshold=.375)
  
  # report
  summary(drt)
  with(drt, plot(as.Date(date), count, "l"))
  abline(5,0)
  par(new=T)
  with(drt, plot(as.Date(date), -1*sums, col= "red", type="l"))
  
#+end_src
*** man-drought_index_stations
#+name:drought_index_stations
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:drought_index_stations

#+end_src

** drought_index_grids
*** R-drought_index_grids
# name:drought_index_grids

## TODO-list: 
# count2 and sums, convert matrices to bricks.
# set it up to work on subsets of the grid and put them back together after

#+name:drought_index_grids
#+begin_src R :session *R* :tangle R/drought_index_grids.r :exports none :eval no :padline no
  #' @name drought_index_grids
  #' @title drought index using grids
  #' @param rasterbrick a stack of grids
  #' @param startyear the start year
  #' @param endyear the end year
  #' @param droughtThreshold the level of dryness
  #' @return dataframe with droughtIndices
  #' @export
  #'
  drought_index_grids <- function(rasterbrick,startyear,endyear,droughtThreshold=.375){
      
    b<-getValuesBlock(rasterbrick, row=500, nrows=5, col=500, ncols=5)
    # TODO estimate the max and min date from the data filenames
    x<-apply(b, 1, function(x) ts(x,start=c(startyear, 01),end=c(endyear,12),frequency=12))
    sixmnthtot<-apply(x, 2, function(x) c(rep(NA,5),x+lag(x,1)+lag(x,2)+lag(x,3)+lag(x,4)+lag(x,5)))
    # TODO it might be faster to use zoo::rollapply,
    # and also we can make the lag length variable
     
    ##rank
    # TODO select for each month ie all Januarys are ranked seperate from Febs etc
    rank <- apply(x, 2, function(x) {return((rank(x)-1)/(length(x)-1))})
    index <- apply(rank, 2, function(x) 8*(x-.5)) #to be a brick
    # .375 is refering to palmer's benchmark but we could let the user vary this
    drought <- apply(x, 2, function(x) x<=quantile(x,droughtThreshold)) 
    indexBelowThreshold <- index*drought #to be a  brick
     
    ##count
    x1 <- index<=-1
    x2 <- apply(x1, 2, function(x) (cumsum(!x) + 1) * x )
    seq <- apply(x1, 2, function(x) seq_along(x))
    match <- apply(x2, 2, function(x) match(x,x))
    count<- (seq - match + 1) * x1 #double check #to be a brick
    return(count)
  }
  
#+end_src
*** test-drought_index_grids
#+name:drought_index_grids
#+begin_src R :session *R* :tangle tests/test-drought_index_grids.r :exports none :eval no
################################################################
# name:drought_index_grids
if(!require(devtools)) install.packages("devtools", depend = T); require(devtools)
install_github("HutchinsonDroughtIndex", "ivanhanigan")
require(HutchinsonDroughtIndex)
wd <- getwd()
setwd("~/data/AWAP_GRIDS/data")
##Lu 13-14 Jan 2014
require(raster); require(rgdal)
##path?
awap.grids = dir(pattern = "grid$", full.names=T)
#  list.files('AWAP_GRIDS', pattern=glob2rx('totals*.grid'), full.names=T)
for(i in 1:12){
  #i = 1
  #file.copy(awap.grids[i], sprintf("foo%s.grid", i))}
  r <- raster(awap.grids[i])
  #str(r)
  #image(r)
  fname <- gsub(".grid",".tif", awap.grids[i])
  # TODO project this please lu!
  writeRaster(r, filename= fname, type = "GTiff")
  #file.remove(awap.grids[i])
}
## for some reason brick or stack only don't work, both together do
awap.grids <- dir(pattern = 'tif')[1:12]
rb <- brick(stack(awap.grids)) #takes too l

## I'm not sure what's more efficient, if changing the drought function 
## to do the cal on matrices or just running the function on the vectors

##option 1 modif function
ct <- drought_index_grids(rasterbrick = rb,startyear = 1900, endyear=1900, droughtThreshold=.375)
plot(ct[,1], type = "l")

#+end_src
*** man-drought_index_grids
#+name:drought_index_grids
#+begin_src R :session *R* :tangle no :exports none :eval no
################################################################
# name:drought_index_grids

#+end_src

** drought_index_future
*** R-drought_index_future
#+begin_src R :session *R* :tangle R/drought_index_future.r :exports none :eval no :padline no
  #' @name drought_index_future
  #' @title Drought Index For Stations for future projected rainfall
  #' @param data a dataframe with date , year, month, rain
  #' @param years the number of years in the time series
  #' @param M number of months in rolling sum, default 6
  #' @param droughtThreshold the level of dryness below which a drought begins
  #' @return dataframe with droughtIndices
  #' @export
  #'
  drought_index_future <- function(data,years,baseline,M=6,droughtThreshold=.375){
  # a drought index based on integrated six-monthly rainfall percentiles.
  # based on Professor Mike Hutchinson's work described in
  # Smith D, Hutchinson M, McArthur R. Climatic and Agricultural Drought: Payments and Policy.
  # Canberra, ACT: Centre for Resource and Environmental Studies, Australian National University. 1992.
  
  # Ivan C Hanigan
  # June 2011.
    
  ################################################################################
  ## Copyright 2011, Ivan C Hanigan <ivan.hanigan@gmail.com> and Michael F Hutchinson
  ## This program is free software; you can redistribute it and/or modify
  ## it under the terms of the GNU General Public License as published by
  ## the Free Software Foundation; either version 2 of the License, or
  ## (at your option) any later version.
  ## 
  ## This program is distributed in the hope that it will be useful,
  ## but WITHOUT ANY WARRANTY; without even the implied warranty of
  ## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
  ## GNU General Public License for more details.
  ## Free Software
  ## Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
  ## 02110-1301, USA
  ################################################################################
  
  
  # my input data are always a data.frame with 4 columns
  # 'date','year','month','rain'
  # we want to only use the baseline to get our percentile values  
  data_baseline <- data[data$year >= min(baseline) & data$year <= max(baseline),]
  #summary(data_baseline)
  nyears <- length(names(table(data_baseline$year)))
  #calculate M month totals
  x <- ts(data_baseline[,4],start=1,end=c(nyears,12),frequency=12)
  x <- zoo::rollapplyr(x, width = M, FUN = sum, fill = NA)
  data_baseline$sixmnthtot <- x
  data_baseline <- na.omit(data_baseline)
  
  nyears2 <- length(names(table(data$year)))
  x2<-ts(data[,4],start=1,end=c(nyears2,12),frequency=12)
  x2<-c(rep(NA,5),x2+lag(x2,1)+lag(x2,2)+lag(x2,3)+lag(x2,4)+lag(x2,5))
  # TASK need to use rollapply?
  data$sixmnthtot <- x2
  data <- na.omit(data)
  
  
  
  # now rank in percentage terms with respect to the rainfall totals 
  # for the same sequence of 6-months over all years of record
  dataout_final=matrix(nrow=0,ncol=7)
  
  for(i in 1:12){
  #  i = 1
          x<-data_baseline[data_baseline$month==i,"sixmnthtot"]
          x2<-data[data$month==i,"sixmnthtot"]
          #x<-na.omit(x)
          # TODO but this is the distribution of the entire series, in and out of the baseline
          y<-(rank(x2)-1)/(length(x2)-1)
          # checkpct<-cbind(data[data$month==i,],y)
          # plot(checkpct$sixmnthtot,checkpct$y)
          # rescale between -4 and +4 to replicate palmer index 
          z<-8*(y-.5)
          # defualts set the threshold at -1 which is upper limit of
          # mild drought in palmer index
          # (3/8ths, or the 37.5th percentile) OF THE BASELINE X
          # TODO so the threshold is on the baseline, but the x2 series is everything
          drought <- x2 <= quantile(x,droughtThreshold)
          # calculate the drought index for any months that fall below the threshold
          # TODO but z is on whole series, but drought is based on exceeding the baseline threshold?
          zd<-z*drought
          # save out to the data
          dataout<-data[data$month==i,]
          dataout$index<-z
          dataout$indexBelowThreshold<-zd
          dataout_final=rbind(dataout_final,dataout)
          }
                  
  data<-dataout_final[order(dataout_final$date),]
  
  # now calculate the indices
  # newnode COUNTS
  data$count<-as.numeric(0)
  # OLD and SLOW
  # for(j in 2:nrow(data)){
          # data$count[j]<-ifelse(data$indexBelowThreshold[j]==0,0,
          # ifelse(data$indexBelowThreshold[j-1]!=0,1+data$count[j-1],
          # 1)
          # )
          # }
  
  # NEW and FAST
  # counts can be done with this funky bit of code 
  x<-data$index<=-1
  xx <- (cumsum(!x) + 1) * x 
  x2<-(seq_along(x) - match(xx, xx) + 1) * x 
  data$count<-x2
  
  # OLD and SLOW enhanced drought revocation threshold 
  # TASK make NEW and FAST? or add as an option?
  # In the enhanced version rather than stop counting when the rescaled percentiles rise above -1.0, 
  # we keep counting the months (or adding the negative anomalies) 
  # if the rescaled percentile is below 0.0 AND the drought threshold has already been reached. 
  # If the threshold has not been reached, then stop counting (or adding) as before 
  # if the rescaled percentile rises above -1.0.
  
  data$count2<-data$count
  # j=1080 # 1980-06
  # data[j,]
  
  for(j in 2:nrow(data)){ 
  data$count2[j] <- if(data$count2[j-1] >= 5 & data$index[j] <= 0){
          data$count2[j-1] + 1
          } else {                
          # ifelse(data$count[j-1] > 0 & data$index[j] < 0, 1+data$count[j-1],
          data$count2[j]
          }
  }
  ############################################################
  # newnode SUMS
  # NEW and FAST? or add as an option?
  data$sums<-as.numeric(0)
  y <- ifelse(data$index >= -1, 0, data$index)
  f <- data$index < -1
  f <- (cumsum(!f) + 1) * f 
  z <- unsplit(lapply(split(y,f),cumsum),f)
  data$sums <- z
  # OLD and SLOW
  # for(j in 2:nrow(data)){
          # data$sums[j]<-ifelse(data$indexBelowThreshold[j]==0,0,
          # ifelse(data$indexBelowThreshold[j-1]!=0,
          # data$indexBelowThreshold[j]+data$sums[j-1],
          # data$indexBelowThreshold[j]))
          # }
          
  # OLD and SLOW
  # TASK make NEW and FAST
  data$sums2<-data$sums
  # j=1069 # 1980-06
  # data[j,]
  
  for(j in 2:nrow(data)){ 
  data$sums2[j] <- if(data$sums2[j-1] <= -17.5 & data$index[j] <= 0){
          data$sums2[j-1] + data$index[j]
          } else {                
          # ifelse(data$count[j-1] > 0 & data$index[j] < 0, 1+data$count[j-1],
          data$sums2[j]
          }
  }
  
  droughtIndices<-data
  return(droughtIndices)
  }
  
#+end_src

*** test-drought_index_future

#+name:drought_index_future
#+begin_src R :session *R* :tangle tests/test-drought_index_future.r :exports none :eval no
  ################################################################
  # name:drought_index_stations
  # for info see
  # https://github.com/ivanhanigan/GARNAUT_CLIMATE_CHANGE_REVIEW
  # drought futures sub project
  
  ## dat <- read.csv("~/projects/GARNAUT_CLIMATE_CHANGE_REVIEW/drought_futures/data/rain_future_estimated_dry.csv", stringsAsFactors = F)
  
  ## names(dat)
  ## head(dat)
  ## tail(dat)
  ## dat$date <- as.Date(paste(dat$year, dat$month, 1, sep = "-"))
  
  ## sds <- names(table(dat$sd_group))
  ## sds
  
  ## # save a test dataset for developing the fucntion with, transfer to
  ## # hutch package
  ## sd_i <- c("Central West", "Murrumbidgee")
  ## dat2 <- dat[dat$year > 1890 & dat$sd_group %in% sd_i, c('sd_group','date','year','month','avrain')]
  ## summary(dat2)
  ## table(dat2$sd_group)
  ## head(dat2, 24)
  ## par(mfrow = c(2,1))
  ## for(sdi in sd_i){
  ##   with(dat2[dat2$sd_group == sdi,],
  ##        plot(date, avrain, type = "l")
  ##        )
  ##   title(sdi)
  ## }
  ## write.csv(dat2, "~/projects/HutchinsonDroughtIndex/inst/extdata/GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv", row.names = F)
  
  library(HutchinsonDroughtIndex)
  
  analyte <- read.csv("~/projects/HutchinsonDroughtIndex/inst/extdata/GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv")
  
  # clean
  str(analyte)
  head(analyte);tail(analyte)
  
  analyte  <- analyte[analyte$sd_group == "Murrumbidgee", c("date", "year", "month","avrain")]
  
  # do
  ## drt <- drought_index_future(
  ##   data=analyte
  ##   ,
  ##   baseline = c(1891, 2008)
  ##   ,
  ##   years=length(names(table(analyte$year)))
  ##   ,
  ##   droughtThreshold=.375
  ##   )
  
  ## # report
  ## par(mfrow = c(2,1))
  ## summary(drt)
  ## with(drt[drt$year > 1980 & drt$year <2010,], plot(as.Date(date), count, "l"))
  ## abline(5,0)
  
  analyte2 <- analyte[analyte$year < 2009,]
  drt2 <- drought_index_stations(
    data=analyte2
    ,
    years=length(names(table(analyte2$year)))
    ,
    droughtThreshold=.375
    )
  with(drt2[drt2$year > 1980 & drt2$year <2010,], plot(as.Date(date), count, "l"))
  abline(5,0)
  
  dev.off()
  #par(new=T)
  #with(drt, plot(as.Date(date), -1*sums, col= "red", type="l"))
  
  
  
  
#+end_src

*** COMMENT scratch
#+name:scratch
#+begin_src R :session *R* :tangle scratch.R :exports none :eval no
#### name:scratch ####
x<-ts(data_baseline[,4],start=1,end=c(nyears,12),frequency=12)
x3<-c(rep(NA,5),x+lag(x,1)+lag(x,2)+lag(x,3)+lag(x,4)+lag(x,5))
library(zoo)
x2 <- x
?rollapply
M=6
qc <- data.frame(x2, rollapplyr(x2, width = M, FUN = sum, fill = NA), x3)
plot(qc[,2], qc[,3])

#+end_src

* Vignettes
** COMMENT DEPRECATED HutchinsonDroughtIndex-code
#+begin_src tex :tangle no :eval no :padline no
\documentclass{article}
%\VignetteIndexEntry{HutchinsonDroughtIndex}
\begin{document}
\SweaveOpts{concordance=TRUE}
\begin{center}
\Large
{\tt HutchinsonDroughtIndex} Package Vignette
\normalsize
\end{center}
The following figure illustrates a sequence of numbers.
<<keep.source=TRUE>>=
library('HutchinsonDroughtIndex')
x <- rnorm(100,1,2)
x
@
\end{document}
#+end_src
** COMMENT vig
#+name:vig
#+begin_src R :session *R* :tangle no :exports none :eval yes
  #### name:vig ####
  setwd("~/projects/HutchinsonDroughtIndex/vignettes")
  library(knitr)
  #dir()
  rmarkdown::render("HutchinsonDroughtIndex.Rmd")
  browseURL("HutchinsonDroughtIndex.html")
#+end_src

#+RESULTS: vig
: 0

*** COMMENT head
#+begin_src R :session *R* :tangle vignettes/HutchinsonDroughtIndex.Rmd :exports none :eval no :padline
---
title: "Hutchinson Drought Index"
author: "Ivan Hanigan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Hutchinson Drought Index}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---
#+end_src
*** COMMENT intro
#+begin_src R :session *R* :tangle vignettes/HutchinsonDroughtIndex.Rmd :exports none :eval no :padline

# Introduction

This is a short introduction to the algorithm.  For fuller explanation see the original chapter of the report, included in the documentation of this package.

#+end_src
*** COMMENT show central west
**** scratch
#+name:scratch
#+begin_src R :session *R* :tangle scratch.R :exports none :eval no
  #### name:scratch ####
  dat <- read.csv("~/projects/HutchinsonDroughtIndex/inst/extdata/GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv")
  
  # better just check that these data are the same as the rainfall I had
  # for the suicide paper
  qc1 <- subset(dat, year <= 2007)
  indir <- "~/Private/SuicideAndDroughtInNSW"
  dir(indir)
  infile <- "suicidedroughtnsw19702007_rates_drought.csv"
  qc2 <- read.csv(file.path(indir, infile))
  names(qc2)
  summary(qc2)
  qc2 <- subset(qc2, sex == "1" & agegp == "30_39")
  qc3 <- merge(qc1, qc2, by.x = c("sd_group", "year", "month"), by.y = c("sd_group", "dthyy", "dthmm"))
  with(qc3, plot(avrain.x, avrain.y))
  abline(0,1)
  # great
  
#+end_src

**** good
#+begin_src R :session *R* :tangle vignettes/HutchinsonDroughtIndex.Rmd :exports none :eval no :padline
  # The southwest slopes and plains region of New South Wales
  
  - The southwest slopes and plains are included as a case study
  - Data from the Garnaut Climate Change Review are provided
  - These apply the future scenarios to the century and assumes that the rainfall pattern will be a repeat with the new conditions  
  - This is obviously too simplistic, but was the method applied in our work in 2008 and of historical interest  
  
  ```{r, eval = F, echo = T}
  library(HutchinsonDroughtIndex)
  projdir <- "~/projects/HutchinsonDroughtIndex/vignettes"
  setwd(projdir)
  indir <- file.path(system.file(package="HutchinsonDroughtIndex"), "extdata")
  dir(indir)
  infile <- "GARNAUT_CLIMATE_CHANGE_drought_futures_dry_southwest_slopes_sd07.csv"
  dat <- read.csv(file.path(indir, infile))
  str(dat)
  dat$date <- as.Date(dat$date)
  sds <- names(table(dat$sd_group))
  png("graphs/rainfall_from_garnaut_review.png")
  par(mfrow = c(2,1))
  for(sdi in sds){
  with(dat[dat$sd_group == sdi,],
    plot(date, avrain, type = "l", col = "grey")
  )
  with(dat[dat$sd_group == sdi,],
    lines(lowess(avrain ~ date, f = 0.02),  col = "blue")
  )
    title(sdi)
  }
  dev.off()
  ```
  
  ![graphs/rainfall_from_garnaut_review.png](graphs/rainfall_from_garnaut_review.png)
  
#+end_src
*** show original method
#+begin_src R :session *R* :tangle vignettes/HutchinsonDroughtIndex.Rmd :exports none :eval no :padline
  # Hutchinsons indices based on entire historical distribution
  
  - The method was first made available as a simple algorithm that looks at the entire distribution of the time series
  
  ```{r, eval = F, echo = T}
  # just use the observed record
  dat2 <- subset(dat, year <= 2007)
  tail(dat2)
  # the function runs on one region only
  #for(sdi in sds){
  sdi <- sds[2]
    indat <- subset(dat2, sd_group == sdi, select = c("date", "year", "month", "avrain"))
    drt <- drought_index_stations(indat, years = length(names(table(indat$year))), M = 6)
  str(drt)
  #}
  
  # when is there an example of the enhancement making a drought longer?
  tail(drt[drt$sums2!=drt$sums,])
  # plot this one
  qc3=drt[drt$year>=1999,]
  
  png(file.path("graphs", sprintf("%sDroughtEnhanced.png",sdi)), res=200, width = 2100, height = 1000)
  par(mfrow=c(4,1),mar=c(2.5,2,1.5,1))
  plot(qc3$date,qc3$avrain,type='l',main=sprintf('%s: raw monthly rainfall', sdi))
  #points(qc3$date,qc3$avrain)
  axis(1,at=as.Date(paste(1994:1998,1,1,sep='-')), labels = 1994:1998)
  lines(qc3$date,qc3$sixmnthtot/6, lwd = 2) #,type='l',main='6-monthly total rainfall')
  points(qc3$date,qc3$sixmnthtot/6)
  axis(1,at=as.Date(paste(1994:1998,1,1,sep='-')), labels = 1994:1998)
  plot(qc3$date,qc3$index,type='l',main='rescaled percentiles -4 to +4, -1 is Palmer Index Mild Drought',ylim=c(-4,4))
  points(qc3$date,qc3$index)
  segments(min(qc3$date),-1,max(qc3$date),-1)
  segments(min(qc3$date),0,max(qc3$date),0,lty=2)
  plot(qc3$date,qc3$sums,type='l',main='sums below -1 threshold, sums of -17.5 or less is a drought')
  points(qc3$date,qc3$sums)
  segments(min(qc3$date),-17.5,max(qc3$date),-17.5)
  axis(1,at=as.Date(paste(1994:1998,1,1,sep='-')), labels = 1994:1998)
  plot(qc3$date,qc3$sums2,type='l',main='enhanced sums of months if already passed threshold of -17.5 and percentiles less than 50%')
  points(qc3$date,qc3$sums2)
  segments(min(qc3$date),-17.5,max(qc3$date),-17.5)
  axis(1,at=as.Date(paste(1994:1998,1,1,sep='-')), labels = 1994:1998)
  dev.off()
  
  ```
  
  ![graphs/MurrumbidgeeDroughtEnhanced.png](graphs/MurrumbidgeeDroughtEnhanced.png)
  
  
#+end_src
** woodland
*** COMMENT Rmd
#+name:Rmd
#+begin_src R :session *R* :tangle reports/kwrt_weather_drought_1888_2014_p141.Rmd :exports none :eval no :padline no
  ---
  title: "kwrt weather drought 1888 2014 p141" 
  author: Ivan C. Hanigan 
  output: 
    html_document: 
      toc: true 
      theme: united 
      number_sections: no     
    pdf_document: 
      toc: true 
      toc_depth: 3 
      highlight: zenburn 
      keep_tex: true 
      number_sections: no         
  documentclass: article 
  classoption: a4paper 
  ---
  
    
  ```{r echo = F, eval=F, results="hide"}
  # func
  setwd("~/data/HutchinsonDroughtIndex/reports/")
  #library(rmarkdown)
  library(knitr)
  library(knitcitations)
  cleanbib()
  options("cite_format"="pandoc")
  #rmarkdown::render("kwrt_weather_drought_1888_2014_p141.Rmd", "all")
  require(markdown)
  knit2html("kwrt_weather_drought_1888_2014_p141.Rmd", options = c("toc", markdown::markdownHTMLOptions(TRUE)), stylesheet = "custom.css")
  browseURL("kwrt_weather_drought_1888_2014_p141.html")
  #system("pandoc -V papersize:'a4paper' -i hanigan-synthesis.html -o hanigan-synthesis.docx")
  ```
  ```{r, echo = F, results = 'hide'}
  # load
  if(!exists("bib")){
  bib <- read.bibtex("~/references/library.bib")
  }
  ```
  
  ## Introduction
  
  This is the code to calculate the Drought Data for the Hutchinson Drought Index  `r citet(bib[["Kokic2006a"]])` application to the Woodland Restoration Plot Network.
  
  First do a quality assurance test with the Prospect Reservoir data, then apply to the woodland restoration plot network spatial locations.
  
  ## Methods
  
  The Drought index is shown in Figure
  X for the SD of Central West NSW
  during a period which includes a strong drought (1979-83). The raw
  monthly rainfall totals are integrated to rolling 6-monthly totals
  (both shown in first panel) which are then ranked into percentiles by
  month and this is rescaled to range between -4 and +4 in keeping with
  the range of the Palmer Index Palmer1965 (second panel). Mild
  drought is below -1 in the Palmer index and so consecutive months
  below this threshold are counted. In the original method 5 or more
  consecutive months was defined as the beginning of a drought, which
  continued until the rescaled percentiles exceed -1 again (third
  panel). The enhanced method imposes a more conservative threshold of
  zero (the median) to break a drought (fourth panel).  There was also
  an alternative method devised by Hutchinson where the rescaled
  percentile values are integrated using conditional cumulative
  sums.
  
  ## Data Sources
  
  ### Bom Station
  - A station from the prospect reservoir
  
  ### AWAP
  - The Bureau of Meteorology has generated a range of gridded meteorological datasets for Australia as a contribution to the Australian Water Availability Project (AWAP). These include monthly precipitation from 1900 to the present.
  - [http://www.bom.gov.au/jsp/awap/](http://www.bom.gov.au/jsp/awap/)
  - Documentation is at [http://www.bom.gov.au/amm/docs/2009/jones.pdf](http://www.bom.gov.au/amm/docs/2009/jones.pdf)
  ### Emast
  
  # Code
  ## Bom Station
  
  ```{r, echo = F, eval =F, results = 'hide'}
  #library(devtools)
  #install_github("ivanhanigan/HutchinsonDroughtIndex")
  library(HutchinsonDroughtIndex)
  setwd("~/data/HutchinsonDroughtIndex/")
  indir <- "data/ad_hoc"
  # go to the bom website to get the link
  # http://www.bom.gov.au/climate/data/index.shtml?map_type=cdio&code=1
  inurl <-"http://www.bom.gov.au/jsp/ncc/cdio/weatherData/av?p_display_type=monthlyZippedDataFile&p_stn_num=67019&p_c=-898321455&p_nccObsCode=139&p_startYear="
  #wd <- getwd()
  #setwd(indir)
  #download.file(inurl, "temp.zip", mode = "wb")
  #unzip("temp.zip")
  #setwd(wd)
  dir(indir)
  df <- read.csv("data/ad_hoc/IDCJAC0001_67019_Data1.csv")
  # create df5
  head(df)
  df$date  <- as.Date(paste(df$Year, df$Month, 1, sep = "-"))
  names(df) <- 
  df <- df[,c("date","Year","Month","Monthly.Precipitation.Total..millimetres.")]
  names(df) <- c("date","year","month","rain")
  tail(df)
  df5 <- subset(df, year < 2015)
  alldates <- merge(1887:2014, 1:12)
  names(alldates)  <- c("year", "month")
  alldates  <- alldates[order(alldates$year),]
  df5 <- merge(alldates, df5, all.x = T)
  df5[is.na(df5$rain),]
  tail(df5)
  # NB the code does not deal with missing months
  # so impute with the mean of that month across al time
  df5[is.na(df5$rain),]
  library(sqldf)
  df5 <- sqldf("
  select t1.year, t1.month, 
   case when rain is null then t2.avg else rain end as rain
  from df5 t1
  join
  (select month, avg(rain) as avg from df5 group by month) t2
  on t1.month = t2.month
  order by t1.year, t1.month
   ")
  str(df5)
  df5$date  <- as.Date(paste(df5$year, df5$month, 1, sep = "-"))
  df5 <- df5[,c("date","year","month","rain")]
  head(df5)
  tail(df5)
  ##############################################
  drt <- drought_index_stations(data=df5,years=length(names(table(df5$year))))
  
  qc3=drt[drt$year>=1979 & drt$year < 1984,]
  
  write.csv(drt, file.path('data/ad_hoc','ProspectReservoir06719Drought8283.csv'), row.names = F)
  
   png(file.path('data/ad_hoc','ProspectReservoir06719Drought8283.png'),res=200,width = 2100, height = 1000)
   par(mfrow=c(4,1),mar=c(2.5,2,1.5,1))
   plot(qc3$date,qc3$rain,type='l',main='Prospect Reservoir (67019) NSW: raw monthly rainfall')
   #points(qc3$date,qc3$rain)
   
   lines(qc3$date,qc3$sixmnthtot/6, lwd = 2) #,type='l',main='6-monthly total rainfall')
   points(qc3$date,qc3$sixmnthtot/6)
   
   plot(qc3$date,qc3$index,type='l',main='Rescaled percentiles -4 to +4, -1 is Palmer Index Mild Drought',ylim=c(-4,4))
   points(qc3$date,qc3$index)
   segments(min(qc3$date),-1,max(qc3$date),-1)
   segments(min(qc3$date),0,max(qc3$date),0,lty=2)
   plot(qc3$date,qc3$count,type='l',main='Counts below -1 threshold, count of 5 or more is a drought')
   points(qc3$date,qc3$count)
   segments(min(qc3$date),5,max(qc3$date),5)
   
   plot(qc3$date,qc3$count2,type='l',main='Enhanced counts of months if already passed count of 5 and percentiles less than 50%')
   points(qc3$date,qc3$count2)
   segments(min(qc3$date),5,max(qc3$date),5)
   dev.off()
  
  ```
  
  ## AWAP
  
  ```{r, echo = F, eval = F, results = 'hide'}
  #### install dependencies
  library(disentangle)
  require(swishdbtools)
  if(!require(raster)) install.packages("raster", dependencies = T); require(raster)
  if(!require(rgdal)) install.packages("rgdal", dependencies = T); require(rgdal)
  library(sqldf)  
  # on linux can install direct, on windoze you configure Rtools
  #require(devtools)
  #install_github("swish-climate-impact-assessment/awaptools")
  require(awaptools)
  #install_github("ivanhanigan/HutchinsonDroughtIndex")
  
  homedir <- "~/data/HutchinsonDroughtIndex/reports"
  outdir <- "~/data/AWAP_GRIDS_RAIN_MONTHLY"
   
  # first make sure there are no left over files from previous runs
  #oldfiles <- list.files(pattern = '.tif', full.names=T) 
  #for(oldfile in oldfiles)
  #{
  #  print(oldfile)
  #  file.remove(oldfile)
  #}
  ################################################
  setwd(homedir)
   
  # local customisations
  workdir  <- outdir
  setwd(workdir)
  dir()
  # don't change this
  # years <- c(2013:2014)
  # lengthYears <- length(years)
  # change this
  startdate <- "2014-01-01"
  enddate <- "2014-12-31"
  # do
  load_monthly(start_date = startdate, end_date = enddate)
   
  # do
  filelist <- dir(pattern = "grid.Z$")
  filelist
  for(fname in filelist)
  {
    #fname <- filelist[1]
    unzip_monthly(fname, aggregation_factor = 1)
    fin <- gsub(".grid.Z", ".grid", fname)
    fout <- gsub(".grid.Z", ".tif", fname)
    r <- raster(fin)
    writeRaster(r, fout, format="GTiff",  overwrite = TRUE)
    file.remove(fin)
  }
   
  cfiles <- list.files(pattern = '.tif', full.names=T) 
  matrix(cfiles)
  ```
  
  
  
  ```{r, echo = F, eval = F, results = 'hide'}
  #library(devtools)
  #install_github("swish-climate-impact-assessment/awaptools")
  library(awaptools)
  #install_github("swish-climate-impact-assessment/swishdbtools")
  library(swishdbtools)
  #install_github("ivanhanigan/gisviz")
  library(gisviz)
  if(!require(raster)) install.packages('raster'); library(raster)
  library(sqldf)
  library(disentangle)
  homedir <- "~/data/HutchinsonDroughtIndex/reports"
  dir(homedir)
  outdir <- "~/data/AWAP_GRIDS_RAIN_MONTHLY"
  setwd(outdir)
  
  locn <- geocode("PROSPECT RESERVOIR NSW")
  epsg <- make_EPSG()
  shp <- SpatialPointsDataFrame(cbind(locn$lon,locn$lat),locn,
                                proj4string=CRS(epsg$prj4[epsg$code %in% '4283']))
  shp@data 
  ##        lon       lat
  ## 1 150.8929 -33.82107
  wd <- getwd()
  setwd(homedir)
  writeOGR(shp, 'prospect.shp', 'prospect', driver='ESRI Shapefile')
  setwd(wd)
  cfiles <-  dir(pattern="tif$")
  cfiles[1:10]
  tail(cfiles)
  for(i in seq_len(length(cfiles))){
    #i <- 1 ## for stepping thru
    gridname <- cfiles[[i]]
    r <- raster(gridname)
    e <- extract(r, shp, df=T)
    e1 <- shp
    e1@data$values <- e[,2]
    e1@data$gridname <- gridname
    # e1@data
    # write to to target file
    write.table(e1@data, file.path(homedir,"kwrt_weather_drought_1888_2014_p141_output.csv"),
      col.names = i == 1, append = i>1 , sep = ",", row.names = FALSE)
  }
  dat <- read.csv(file.path(homedir,"kwrt_weather_drought_1888_2014_p141_output.csv"))
  head(dat)
  tail(dat)
  qc2 <- read.csv("~/data/HutchinsonDroughtIndex/data/ad_hoc/IDCJAC0001_67019_Data1.csv")
  names(qc2) <- lcu(names(qc2))
  head(qc2)
  tail(qc2)
  dat$raster_layer <- as.character(dat$gridname)
  dat$date <- matrix(unlist(strsplit(dat$raster_layer, "_")), ncol = 2, byrow=TRUE)[,2]
  head(dat)
  dat$date <- gsub(".tif","",dat$date)
  head(dat )
  dat$date <- paste(substr(dat$date,1,4), substr(dat$date,5,6), substr(dat$date,7,8), sep = "-")
  head(dat )
  dat$year <- substr(dat$date,1,4)
  dat$month <- substr(dat$date,6,7)
  dat$year <- as.numeric(dat$year)
  dat$month <- as.numeric(dat$month)
  dat$date <- as.Date(dat$date)
  str(dat)
  
  qc <- dat
  qc3 <- sqldf("select * from qc left join qc2 on qc.year = qc2.year and
    qc.month = qc2.month")
  head(qc3)
  tail(qc3)
  
  #png(file.path(homedir,"kwrt_weather_drought_1888_2014_p141_output1.png"))
  ##with(qc3, plot(monthly_precipitation_total_millimetres_, values))
  #dev.off()
  
  ## png(file.path(homedir,"kwrt_weather_drought_1888_2014_p141_output2.png"))
  ## with(qc3, plot(as.Date(date), values, type = "l"))
  ## with(qc3, lines(as.Date(date), monthly_precipitation_total_millimetres_, col = "blue"))
  ## dev.off()
  
  qc3[is.na(qc3$monthly_precipitation_total_millimetres_),]
  
  require(HutchinsonDroughtIndex)
  head(qc3);tail(qc3)
  qc4 <- sqldf("select * from qc3 where year < 2015")
  head(qc4);tail(qc4)
  qc4$rain <- qc4$values
  as.data.frame(table(qc4$year))
  indat <- qc4[,c("date","year","month","rain")]
  str(indat)
  indat[(nrow(indat) - 20):nrow(indat),]
  
  
  drt <- drought_index_stations(data=indat,
  years=length(names(table(indat$year)))
  )
  head(drt)
  tail(drt)
  str(drt)
  write.csv(drt, "kwrt_weather_drought_1888_2014_p141_output_awap.csv", row.names = F)
  qc3 <- drt[drt$year>=1979 & drt$year < 1984,]
  
  png(file.path(homedir,"kwrt_weather_drought_1888_2014_p141_output_awap.png"))
  par(mfrow=c(4,1),mar=c(2.5,2,1.5,1))
   plot(qc3$date,qc3$rain,type='l',main='Prospect Reservoir (67019) NSW: raw monthly rainfall (AWAP)')
   #points(qc3$date,qc3$rain)
   
   lines(qc3$date,qc3$sixmnthtot/6, lwd = 2) #,type='l',main='6-monthly total rainfall')
   points(qc3$date,qc3$sixmnthtot/6)
   
   plot(qc3$date,qc3$index,type='l',main='Rescaled percentiles -4 to +4, -1 is Palmer Index Mild Drought',ylim=c(-4,4))
   points(qc3$date,qc3$index)
   segments(min(qc3$date),-1,max(qc3$date),-1)
   segments(min(qc3$date),0,max(qc3$date),0,lty=2)
   plot(qc3$date,qc3$count,type='l',main='Counts below -1 threshold, count of 5 or more is a drought')
   points(qc3$date,qc3$count)
   segments(min(qc3$date),5,max(qc3$date),5)
   
   plot(qc3$date,qc3$count2,type='l',main='Enhanced counts of months if already passed count of 5 and percentiles less than 50%')
   points(qc3$date,qc3$count2)
   segments(min(qc3$date),5,max(qc3$date),5)
  dev.off()
  
  
  ```
  
  ## EMAST
  
  ```{r, echo =F, eval = F, results='hide'}
  
  setwd("~/data/brains-prod/home/ivan_hanigan/data/grids_emast/data")
  # ref http://www.emast.org.au/observations/climate/
  #install.packages("ncdf", type = "source", configure.args="--with-netcdf-include=/usr/include")
  require(ncdf)
  
  ## Loading required package: ncdf
  
  #install.packages("raster", dependencies = T)
  require(raster)
  
  ## Loading required package: raster
  ## Loading required package: sp
  
  # install.packages("rgdal")
  require(rgdal)
  
  # Loading required package: rgdal
  # rgdal: version: 0.9-1, (SVN revision 518)
  # Geospatial Data Abstraction Library extensions to R successfully loaded
  # Loaded GDAL runtime: GDAL 1.9.2, released 2012/10/08
  # Path to GDAL shared files: /usr/share/gdal
  # Loaded PROJ.4 runtime: Rel. 4.8.0, 6 March 2012, [PJ_VERSION: 480]
  # Path to PROJ.4 shared files: (autodetected)
  
  #if extracting for points shapefile
  require(ggmap)
  require(rgdal)
  locn <- geocode("Prospect Reservoir NSW")
  # this uses google maps API, better check this
  
  ## Treat data frame as spatial points
  epsg <- make_EPSG()
  shp <- SpatialPointsDataFrame(cbind(locn$lon,locn$lat),locn,
                                proj4string=CRS(epsg$prj4[epsg$code %in% '4283']))
  str(shp)
  shp@data
  # #writeOGR(shp, 'test.shp', 'test', driver  = "ESRI Shapefile")
  # 
  # #shp <- readOGR(dsn="test.shp", layer='test')
  # #plot(shp, add = T)
  # 
  # # a loop through days, see comment sections that print for debugging
  # strt <-'2012-01-01'
  # end <- '2012-01-04'
  # dates <- seq(as.Date(strt),as.Date(end),1)          
  # dates
  # 
  # ## [1] "2012-01-01" "2012-01-02" "2012-01-03" "2012-01-04"
  # 
  # # if extracting to shp then set up an output dataframe to collect
  # dat_out <- as.data.frame(matrix(nrow = 0, ncol = 4))
  # # else just plots
  # par(mfrow = c(2,2))
  # for(i in 1:length(dates)){
  #   #  i=1
  #   date_i <- dates[i]
  #   infile <- sprintf("http://dapds00.nci.org.au/thredds/dodsC/rr9/Climate/eMAST/ANUClimate/0_01deg/v1m0_aus/day/land/tmin/e_01/2012/eMAST_ANUClimate_day_tmin_v1m0_%s.nc", gsub("-", "", date_i))
  #   
  #   nc <- open.ncdf(infile)
  #   vals <- get.var.ncdf(nc, varid="air_temperature")
  #   nc.att <- nc$var$air_temperature
  #   xmin <- min(nc.att$dim[[1]]$vals)
  #   xmax <- max(nc.att$dim[[1]]$vals)
  #   ymin <- min(nc.att$dim[[2]]$vals)
  #   ymax <- max(nc.att$dim[[2]]$vals)
  #   
  #   print(c(xmin,xmax))
  #   print(c(ymin,ymax))
  #   
  #   r <- raster(t(vals),
  #               xmn=xmin, xmx=xmax,
  #               ymn=ymin, ymx=ymax)
  #   #str(r)
  #   plot(r)
  #   title(date_i)
  #   #image(r)
  #   e <- extract(r, shp, df=T)
  #   #str(e) 
  #   e1 <- shp@data
  #   e1$date <- date_i
  #   e1$values <- e[,2]
  #   dat_out <- rbind(dat_out, as.data.frame(e1))
  # }
  # dat_out
  # 
  # # monthly
  # "http://dap.nci.org.au/thredds/remoteCatalogService?command=subset&catalog=http://dapds00.nci.org.au/thredds/catalog/rr9/Climate/eMAST/ANUClimate/0_01deg/v1m0_aus/mon/land/prec/e_01/1970_2012/catalog.xml&dataset=rr9/Climate/eMAST/ANUClimate/0_01deg/v1m0_aus/mon/land/prec/e_01/1970_2012/eMAST_ANUClimate_mon_prec_v1m0_197001.nc"
  # strt <-'1976-01-01'
  # end <- '2012-12-31'
  # #dates <- paste(strt:end, 1:12)
  # dates <- seq(as.Date(strt),as.Date(end),31) 
  yy <- as.data.frame(1970:2012)
  mm <- as.data.frame(c("01","02","03","04","05","06","07","08","09","10","11","12"))
  library(sqldf)
  dates <- sqldf("select * from yy, mm")
  head(dates)
  dates <- paste(dates[,1], dates[,2], sep = "")
  head(dates)
  dates[1:10]
  #dat_out <- as.data.frame(matrix(nrow = 0, ncol = 4))
  # else just plots
  #par(mfrow = c(2,2))
  # setwd("data")
  cfiles <-  dir(pattern="tif$")
  cfiles[1:10]
  tail(cfiles)
  length(cfiles)
  dates[426]
  system("df -h")
  ## for(i in 426:length(dates)){
  ##   #  i=183
  ##   date_i <- gsub("-", "", substr(dates[i],1,7))
  ##   print(date_i)
  ##   infile <- sprintf("http://dapds00.nci.org.au/thredds/dodsC/rr9/Climate/eMAST/ANUClimate/0_01deg/v1m0_aus/mon/land/prec/e_01/1970_2012/eMAST_ANUClimate_mon_prec_v1m0_%s.nc", gsub("-", "", date_i))
  ##   #infile
  ##   nc <- open.ncdf(infile)
  ##   #str(nc)
  ##   vals <- get.var.ncdf(nc, varid="lwe_thickness_of_precipitation_amount")
  ##   nc.att <- nc$var$lwe_thickness_of_precipitation_amount
  ##   xmin <- min(nc.att$dim[[1]]$vals)
  ##   xmax <- max(nc.att$dim[[1]]$vals)
  ##   ymin <- min(nc.att$dim[[2]]$vals)
  ##   ymax <- max(nc.att$dim[[2]]$vals)
    
  ##   #  print(c(xmin,xmax))
  ##   #  print(c(ymin,ymax))
    
  ##   r <- raster(t(vals),
  ##               xmn=xmin, xmx=xmax,
  ##               ymn=ymin, ymx=ymax)
  ##   #str(r)
  ##   #  plot(r)
  ##   #  title(date_i)
  ##   writeRaster(r, paste("precipitation_",date_i,".tif",sep=''), format="GTiff")
                
  ##   #image(r)
  ##   #e <- extract(r, shp, df=T)
  ##   #str(e) 
  ##   #e1 <- shp@data
  ##   #e1$date <- date_i
  ##   #e1$values <- e[,2]
  ##   #dat_out <- rbind(dat_out, as.data.frame(e1))
  ##   #write.table(e1, file.path("kwrt_weather_drought_1888_2014_p141_output_grids_emast.csv"),
  ##   #            col.names = i == 1, append = i>1 , sep = ",", row.names = FALSE)
  ##   Sys.sleep(time = 2)
  ## }
  #dat_out
  
  
  cfiles <-  dir(pattern="tif$")
  cfiles[1:10]
  tail(cfiles)
  for(i in seq_len(length(cfiles))){
    #i <- 1 ## for stepping thru
    gridname <- cfiles[[i]]
    r <- raster(gridname)
    e <- extract(r, shp, df=T)
    e1 <- shp
    e1@data$values <- e[,2]
    e1@data$gridname <- gridname
    # e1@data
    # write to to target file
    write.table(e1@data, file.path("~/data/HutchinsonDroughtIndex/reports", "kwrt_weather_drought_1888_2014_p141_output_grids_emast.csv"),
                col.names = i == 1, append = i>1 , sep = ",", row.names = FALSE)
  }
  
  ############################################################################################
  setwd("~/data/HutchinsonDroughtIndex/reports")
  dir(pattern="csv")
  dat <- read.csv("kwrt_weather_drought_1888_2014_p141_output_grids_emast.csv")
  head(dat)
  tail(dat)
  
  dat$raster_layer <- as.character(dat$gridname)
  dat$date <- matrix(unlist(strsplit(dat$raster_layer, "_")), ncol = 2, byrow=TRUE)[,2]
  head(dat)
  dat$date <- gsub(".tif","",dat$date)
  head(dat )
  dat$date <- paste(substr(dat$date,1,4), substr(dat$date,5,6), 1, sep = "-")
  head(dat )
  dat$year <- substr(dat$date,1,4)
  dat$month <- substr(dat$date,6,7)
  dat$year <- as.numeric(dat$year)
  dat$month <- as.numeric(dat$month)
  dat$date <- as.Date(dat$date)
  str(dat)
  
  
  qc <- dat
  
  
  require(HutchinsonDroughtIndex)
  qc$rain <- qc$values
  as.data.frame(table(qc$year))
  indat <- qc[,c("date","year","month","rain")]
  str(indat)
  indat[(nrow(indat) - 20):nrow(indat),]
  
  
  drt <- drought_index_stations(data=indat,
                                years=length(names(table(indat$year)))
  )
  head(drt)
  tail(drt)
  str(drt)
  write.csv(drt, "kwrt_weather_drought_1888_2014_p141_output_grids_emast2.csv", row.names=F)
  
  
  qc3 <- drt[drt$year>=1979 & drt$year < 1984,]
  
  png(file.path(homedir,"kwrt_weather_drought_1888_2014_p141_output_emast.png"))
  par(mfrow=c(4,1),mar=c(2.5,2,1.5,1))
  plot(qc3$date,qc3$rain,type='l',main='Prospect Reservoir (67019) NSW: raw monthly rainfall')
  #points(qc3$date,qc3$rain)
  
  lines(qc3$date,qc3$sixmnthtot/6, lwd = 2) #,type='l',main='6-monthly total rainfall')
  points(qc3$date,qc3$sixmnthtot/6)
  
  plot(qc3$date,qc3$index,type='l',main='Rescaled percentiles -4 to +4, -1 is Palmer Index Mild Drought',ylim=c(-4,4))
  points(qc3$date,qc3$index)
  segments(min(qc3$date),-1,max(qc3$date),-1)
  segments(min(qc3$date),0,max(qc3$date),0,lty=2)
  plot(qc3$date,qc3$count,type='l',main='Counts below -1 threshold, count of 5 or more is a drought')
  points(qc3$date,qc3$count)
  segments(min(qc3$date),5,max(qc3$date),5)
  
  plot(qc3$date,qc3$count2,type='l',main='Enhanced counts of months if already passed count of 5 and percentiles less than 50%')
  points(qc3$date,qc3$count2)
  segments(min(qc3$date),5,max(qc3$date),5)
  dev.off()
  
  
  
  ```
  
  ## Results
  
  ### Combine the three time-series
  
  ```{r, echo = F, results = 'hide', eval = F}
  library(EML)
  
  indir1 <- '../data/ad_hoc'
  dir(indir1)
  infile1 <- 
  file.path(indir1,'ProspectReservoir06719Drought8283.csv')
  dir("reports",pattern="csv")
  infile2 <- "kwrt_weather_drought_1888_2014_p141_output_awap.csv"            
  infile3 <- "kwrt_weather_drought_1888_2014_p141_output_grids_emast2.csv"
  
  dat <- read.csv(infile1)
  str(dat)
  
  dat_qc <- dat[,c("year", "month","rain")]
  names(dat_qc) <- gsub("rain","rain_bom_stn", names(dat_qc))
  
  dat_out <- dat[,c("year", "month","count2", "sums2")]
  names(dat_out) <- gsub("count2","duration_bom_stn", names(dat_out))
  names(dat_out) <- gsub("sums2","severity_bom_stn", names(dat_out))
  dat_out$duration_bom_stn_declared <- ifelse(dat_out$duration_bom_stn > 4, "TRUE", "FALSE")
  dat_out$severity_bom_stn_declared <- ifelse(dat_out$severity_bom_stn < -17.5, "TRUE", "FALSE")
  
  str(dat_qc)
  str(dat_out)
  
  ############################3
  # awap
  #setwd("reports")
  dat <- read.csv(infile2)
  str(dat)
  dat_qc <- merge(dat_qc, dat[,c("year", "month","rain")], by = c("year","month"), all.x = T)
  
  names(dat_qc) <- gsub("rain$","rain_awap", names(dat_qc))
  str(dat_qc)
  head(dat_qc); tail(dat_qc)
  str(dat_out)
  dat_out <- merge(dat_out, dat[,c("year", "month","count2", "sums2")], by =c("year","month"), all.x =T)
  names(dat_out) <- gsub("count2","duration_awap", names(dat_out))
  names(dat_out) <- gsub("sums2","severity_awap", names(dat_out))
  dat_out$duration_awap_declared <- ifelse(dat_out$duration_awap > 4, "TRUE", "FALSE")
  dat_out$severity_awap_declared <- ifelse(dat_out$severity_awap < -17.5, "TRUE", "FALSE")
  
  str(dat_qc)
  str(dat_out)
  
  
  ##################################
  # emast
  dat <- read.csv(infile3)
  str(dat)
  head(dat); tail(dat)
  
  dat_qc <- merge(dat_qc, dat[,c("year", "month","rain")], by = c("year","month"), all.x = T)
  
  names(dat_qc) <- gsub("rain$","rain_emast", names(dat_qc))
  str(dat_qc)
  head(dat_qc); tail(dat_qc)
  str(dat_out)
  dat_out <- merge(dat_out, dat[,c("year", "month","count2", "sums2")], by =c("year","month"), all.x =T)
  names(dat_out) <- gsub("count2","duration_emast", names(dat_out))
  names(dat_out) <- gsub("sums2","severity_emast", names(dat_out))
  dat_out$duration_emast_declared <- ifelse(dat_out$duration_emast > 4, "TRUE", "FALSE")
  dat_out$severity_emast_declared <- ifelse(dat_out$severity_emast < -17.5, "TRUE", "FALSE")
  
  str(dat_qc)
  write.csv(dat_qc, "kwrt_weather_drought_1888_2014_p141_rainfall_combined_qc.csv", row.names=F)
  png("qc_pairs.png")
  pairs(dat_qc[,3:5])
  dev.off()
  
  str(dat_out)
  library(disentangle)
  outfile <- "kwrt_weather_drought_1888_2014_p141_predicted_declarations.csv"
  
    unit_defs <- reml_boilerplate(dat_out)
    # you just got a quick and dirty unit_defs, these need to be made proper in morpho
    # we can get the col names easily
    col_defs <- names(dat_out)
  ds <- data.set(dat_out,
                 col.defs = col_defs,
                 unit.defs = unit_defs
                 )
  # now write EML metadata file
  eml_config(creator="Ivan Hanigan <ivanhanigan@gmail.com>")
  eml_write(ds,
            file = gsub(".csv", ".xml", outfile),
            title = "NA"
            )
    tempfile <- dir(pattern="^table_")
    # rename the CSV file.
    file.rename(tempfile, outfile)
  
  
  ```
  
  ### Compare the results
  
  ```{r, echo = F, eval = F, results = "hide"}
  dir()
  infile <- "kwrt_weather_drought_1888_2014_p141_rainfall_combined_qc.csv"
  dat_qc <- read.csv(infile)
  png("qc_pairs.png")
  pairs(dat_qc[,3:5])
  dev.off()
  
  
  infile <- "kwrt_weather_drought_1888_2014_p141_predicted_declarations.csv"
  dat <- read.csv(infile)
  str(dat)
  
  subset(dat, year == 1982 | year == 1983)
  
  
  qc3 <- dat[dat$year>=1979 & dat$year < 1984,]
  qc3$date <- as.Date(paste(qc3$year, qc3$month, 1, sep = "-"))
  
  png(file.path('kwrt_weather_drought_1888_2014_p141_rainfall_combined_qc.png'),res=200,width = 2100, height = 1000)
    plot(qc3$date,qc3$duration_bom_stn,type='l',main='Drought Index')
   points(qc3$date,qc3$duration_bom_stn)
   segments(min(qc3$date),4.5,max(qc3$date),4.5)
  
   points(qc3$date,qc3$duration_awap, col = 'blue', pch = 16, cex = 0.5)
  
   points(qc3$date,qc3$duration_emast, col = 'red', pch = 1, cex = 2)
  legend("topright", legend= c("Station", "AWAP", "EMAST"), col = c('black', 'blue', 'red'), pch = c(1, 16, 1), pt.cex = c(1,.5,2))
  dev.off()
  
  ```
  
  Shown in Figure Y is the results
  
  ![alttext](kwrt_weather_drought_1888_2014_p141_rainfall_combined_qc.png)
  
  ### compare old publication
  
  ```{r, results = 'hide', echo = FALSE, eval = F}
  library(swishdbtools)
  ch <- connect2postgres2("ewedb")
  
  ##        lon       lat
  ## 1 150.8929 -33.82107
  
  qc <- dbGetQuery(ch,
  "select t2.*,t1.*
  from bom_grids.rain_nsw_1890_2008_4 as t1 join (
  select bom_grids.grid_nsw.*
  from bom_grids.grid_nsw
  where st_intersects(
  st_GeomFromText(
  'POINT('||
  150.8929  ||
  ' '||
  -33.82107 ||')'
  ,4283)
  ,bom_grids.grid_nsw.the_geom)
  ) as t2
  on t1.gid=t2.gid
  ")
  
  str(qc)
  paste(names(qc), sep = "", collapse = "','")
  namlist  <- c('year','month','rain','sum','count')
  qc <- qc[,namlist]
  head(qc)
  
  infile <- "kwrt_weather_drought_1888_2014_p141_rainfall_combined_qc.csv"
  dat_qc <- read.csv(infile)
  str(dat_qc)
  infile <- "kwrt_weather_drought_1888_2014_p141_predicted_declarations.csv"
  dat <- read.csv(infile)
  str(dat)
  
  dat_qc2 <- merge(dat,dat_qc)
  str(dat_qc2)
  str(qc)
  
  dat_qc2  <- merge(qc, dat_qc2)
  head(dat_qc2)
  par(mfrow = c(1,3))
  with(dat_qc2,
       plot(rain, rain_bom_stn)
       )
  with(dat_qc2,
       plot(rain, rain_awap)
       )
  with(dat_qc2,
       plot(rain, rain_emast)
       )
  
  head(dat)
  library(sqldf)
  dat_qc2 <- sqldf("select * from dat_qc2 order by year, month", drv = "SQLite")
  write.csv(dat_qc2, "kwrt_weather_drought_1888_2014_p141_predicted_declarations_with_old.csv", row.names = F)
  dat_qc2$timevar <- as.Date(paste(dat_qc2$year, dat_qc2$month, 1, sep = "-"))
  
  dat_qc2$old <- ifelse(dat_qc2$count > 4, TRUE, FALSE)
  head(dat_qc2)
  
  png("kwrt_weather_drought_1888_2014_p141_drought_compare.png", height = 800, width = 1300, res = 145)
  with(dat_qc2,
       plot(timevar, rain, type = "l")
       )
  par(new=T)
  plot(dat_qc2$timevar, dat_qc2$duration_bom_stn_declared, type = "n", ylab="", xlab = "", axes = F)
  points(dat_qc2$timevar, dat_qc2$duration_bom_stn_declared, col = "red", cex = .7, pch = 16)
  par(new=T)
  plot(dat_qc2$timevar, dat_qc2$duration_bom_stn_declared+.1, type = "n", ylab="", xlab = "", axes = F)
  points(dat_qc2$timevar, dat_qc2$old, col = "orange", cex = .7, pch = 16)
  par(new=T)
  plot(dat_qc2$timevar, dat_qc2$duration_bom_stn_declared+0.2, type = "n", ylab="", xlab = "", axes = F)
  points(dat_qc2$timevar, dat_qc2$duration_awap_declared, col = "blue", cex = .7, pch = 16)
  par(new=T)
  plot(dat_qc2$timevar, dat_qc2$duration_bom_stn_declared+0.3, type = "n", ylab="", xlab = "", axes = F)
  points(dat_qc2$timevar, dat_qc2$duration_emast_declared, col = "green", cex = .7, pch = 16)
  legend("bottomleft", legend = c("station", "bom_barnes",  "awap", "emast"), pch = c(16,16,16 ,16), col = c("red", "orange", "blue", "green"))
  title("Comparison of Hutchinson's Drought Index at Prospect Reservoir 1890 - 2008")
  dev.off()
  
  
  ```
  
  ## Conclusions
  
  The end
  
  ## References
  
  ```{r, results = 'asis', echo = FALSE, eval = F}
  bibliography()
  ```
  
#+end_src

* Worklog
** 2015-11-08 results from Ivan Re: build test dataset for NSW SDs using AWAP historic + CSIRO future
- aim is to average gridded awap data on nswsd07, just like the garnaut stuff

# 8th november preparatory work

## awap
- AWAP is good updating whereas emast is now stopped
-  A script is to download the spatial grids of the Australian Water Availability Project
- http://www.bom.gov.au/jsp/awap/
- https://github.com/swish-climate-impact-assessment/AWAP_GRIDS

## access
- Australian Community Climate and Earth System Simulator (ACCESS) is good future 
- http://www.csiro.au/en/Research/OandA/Areas/Assessing-our-climate/CAWCR/ACCESS

** 2015-11-09 results from Ivan Re: predicting future droughts, using better historical data
# 9th Nov 
- get woodland drought codes from gh-pages, import to main.org
- prepping awap data on SDs for Lu to help get future climate from ACCESS 
- do that work in the awap_grids project, and then this will feed into the opensoft paper
- downloaded all awap data again on swish-R
- extract the vals for the NSWSD11, (maxed out the swish-R RAM?  fail, stop)
- change func to handle variable years, no need for ts anymore
- calc drought on SDs with latest function
- had to stop, keep using the garnaut stuff as it is ok
** 2016-08-25-drought-in-iraq
~/projects/ivanhanigan.github.com.raw/_posts/2016-08-25-drought-in-iraq.md
#+name:drought-in-iraq-header
#+begin_src R :session *R* :tangle reports/databag_drought.R :exports none :eval no :padline no
  library(HutchinsonDroughtIndex)
  projdir <- "~/projects/HutchinsonDroughtIndex"
  setwd(projdir)
  dir()
  indir  <- "data/ad_hoc"
  infile <- "databag.csv"
  
  dat  <- read.delim(file.path(indir,infile), sep = ";")
  str(dat)
  dat$date  <- as.Date(paste(dat$YEAR, dat$MONTH, 1, sep = "-"))
  plot(dat$date, dat$precip, type = "l")
  # check there are 12 obs per year
  table(dat$YEAR)
  
  
  
  names(dat)
  dat <- dat[,c("date","YEAR","MONTH","precip")]
  names(dat) <- c("date","year","month","rain")
  tail(dat)
  head(dat)
  
  ##############################################
  # do the drought algorithm
  drt <- drought_index_stations(data=dat,years=length(names(table(dat$year))))
  head(drt)
  par(mfrow = c(2,1))
  plot(drt$date, drt$rain, type = "l")
  plot(drt$date, drt$count2, type = "l")
  segments(min(drt$date), 5, max(drt$date), 5)
  
  write.csv(drt, file.path('data/ad_hoc/databag_drought_20160825.csv'), row.names = F)
  
  # QC
  # http://www.cbsnews.com/news/droughts-the-next-great-threat-to-iraq/
  # this says drought from 2007 to 2010
  qc <- drt[drt$year>=2000 & drt$year < 2013,]
  qc
  
  
  png(file.path('data/ad_hoc','databag.png'),res=200,width = 2100, height = 1000)
  par(mfrow=c(4,1),mar=c(2.5,2,1.5,1))
  plot(qc$date,qc$rain,type='l',main='Data bag: raw monthly rainfall')
  #points(qc$date,qc$rain)
  
  lines(qc$date,qc$sixmnthtot/6, lwd = 2) #,type='l',main='6-monthly total rainfall')
  points(qc$date,qc$sixmnthtot/6)
  
  plot(qc$date,qc$index,type='l',main='Rescaled percentiles -4 to +4, -1 is Palmer Index Mild Drought',ylim=c(-4,4))
  points(qc$date,qc$index)
  segments(min(qc$date),-1,max(qc$date),-1)
  segments(min(qc$date),0,max(qc$date),0,lty=2)
  plot(qc$date,qc$count,type='l',main='Counts below -1 threshold, count of 5 or more is a drought')
  points(qc$date,qc$count)
  segments(min(qc$date),5,max(qc$date),5)
  
  plot(qc$date,qc$count2,type='l',main='Enhanced counts of months if already passed count of 5 and percentiles less than 50%')
  points(qc$date,qc$count2)
  segments(min(qc$date),5,max(qc$date),5)
  dev.off()
  
#+end_src
